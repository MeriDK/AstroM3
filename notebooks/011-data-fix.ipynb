{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73d9d7fd-e89d-4a95-ac87-b4adabd76099",
   "metadata": {},
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "635a0746-a5cf-410b-a7a5-d32e493b79ce",
   "metadata": {},
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "from core.multimodal.dataset import collate_fn, ASASSNVarStarDataset\n",
    "from core.multimodal.dataset2 import VGDataset\n",
    "from models.Informer import Informer"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "efcf023b-3b2b-4090-ba46-1575338d0f1b",
   "metadata": {},
   "source": [
    "CLASSES = ['CWA', 'CWB', 'DCEP', 'DCEPS', 'DSCT', 'EA', 'EB', 'EW',\n",
    "           'HADS', 'M', 'ROT', 'RRAB', 'RRC', 'RRD', 'RVA', 'SR']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f02a7c0-1e5c-406e-b644-480a6624f1e0",
   "metadata": {},
   "source": [
    "def get_config(random_seed):\n",
    "\n",
    "    config = {\n",
    "        'project': 'vband-classification',\n",
    "        'random_seed': random_seed,\n",
    "        'use_wandb': True,\n",
    "        'save_weights': True,\n",
    "        'weights_path': f'/home/mariia/AstroML/weights/{datetime.now().strftime(\"%Y-%m-%d-%H-%M\")}',\n",
    "        'use_pretrain': None,\n",
    "        \n",
    "        # Data\n",
    "        'dataset_class': 'VGDataset',   # 'VGDataset' or 'ASASSNVarStarDataset'\n",
    "        'data_root': '/home/mariia/AstroML/data/asassn',\n",
    "        'vg_file': 'v.csv',     # 'vg_combined.csv', 'v.csv', 'g.csv'\n",
    "        'scales': 'mean-mad',    # 'scales.json', 'mean-std', 'mean-mad'\n",
    "        'seq_len': 1500,\n",
    "        'min_samples': None,\n",
    "        'max_samples': 20000,\n",
    "        'classes': CLASSES,\n",
    "        'phased': True,\n",
    "        'periodic': True,\n",
    "        'clip_outliers': False,\n",
    "        'aux': True,\n",
    "\n",
    "        # Model\n",
    "        'model': 'informer',  # 'informer' or 'vanilla'\n",
    "        'encoder_layers': 2,\n",
    "        'd_model': 128,\n",
    "        'dropout': 0.2,\n",
    "        'feature_size': 3,\n",
    "\n",
    "        # Informer\n",
    "        'n_heads': 4,\n",
    "        'd_ff': 512,\n",
    "\n",
    "        # Time Series Transformer\n",
    "        'prediction_length': 20,    # doesn't matter for classification, but it's required by hf\n",
    "        'num_time_features': 1,\n",
    "        'num_static_real_features': 0,  # if 0 we don't use real features\n",
    "        'distribution_output': 'normal',\n",
    "        'scaling': None,\n",
    "        'encoder_layerdrop': 0,\n",
    "        'attention_dropout': 0,\n",
    "        'activation_dropout': 0,\n",
    "\n",
    "        # Training\n",
    "        'batch_size': 32,\n",
    "        'lr': 1e-3,\n",
    "        'weight_decay': 0.01,\n",
    "        'epochs': 50,\n",
    "        'optimizer': 'AdamW',   # 'AdamW', 'RAdam'\n",
    "\n",
    "        # Learning Rate Scheduler\n",
    "        'factor': 0.3,\n",
    "        'patience': 10,\n",
    "    }\n",
    "\n",
    "    if config['aux']:\n",
    "        config['feature_size'] += 3     # + (mean, std, period)\n",
    "\n",
    "    return config"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64c505f1-da43-4782-a7ae-3c98d3b3a782",
   "metadata": {},
   "source": [
    "config = get_config(42)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cff5294e-de6c-4515-b541-ec36a015001a",
   "metadata": {},
   "source": [
    "train_dataset = VGDataset(\n",
    "    config['data_root'], config['vg_file'], split='train', seq_len=config['seq_len'],\n",
    "    min_samples=config['min_samples'], max_samples=config['max_samples'], phased=config['phased'],\n",
    "    periodic=config['periodic'], classes=config['classes'], clip=config['clip_outliers'],\n",
    "    random_seed=config['random_seed'], scales=config['scales'], aux=config['aux']\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e17478e-6897-4672-821d-4f95dbca57de",
   "metadata": {},
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "704072cc-d83b-42e0-9cb7-cd0ff46373dd",
   "metadata": {},
   "source": [
    "model = Informer(enc_in=config['feature_size'], d_model=config['d_model'], dropout=config['dropout'], factor=1,\n",
    "                 output_attention=False, n_heads=config['n_heads'], d_ff=config['d_ff'],\n",
    "                 activation='gelu', e_layers=config['encoder_layers'], seq_len=config['seq_len'],\n",
    "                 num_class=train_dataset.num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d2eb394-4141-4292-af6f-a1d2f1303680",
   "metadata": {},
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "d60e14e9-0916-47ac-8a7c-f430b8043de3",
   "metadata": {},
   "source": [
    "for i in tqdm(range(len(train_dataset))):\n",
    "    X = train_dataset.get_vlc(train_dataset.df.iloc[i]['name'])\n",
    "    mean = X[:, 1].mean()\n",
    "    std = stats.median_abs_deviation(X[:, 1])\n",
    "    period = train_dataset.df.iloc[i]['period']\n",
    "\n",
    "    if mean < 0.001:\n",
    "        print(i, mean)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c24c7ed8-4284-482a-992f-a6411494a73b",
   "metadata": {},
   "source": [
    "type(mean)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "453c6b23-b88b-4d23-810c-0ce1f9c5dd45",
   "metadata": {},
   "source": [
    "losses = []\n",
    "\n",
    "for X, mask, y in tqdm(train_dataloader):\n",
    "    X, mask, y = X.to(device), mask.to(device), y.to(device)\n",
    "    out = model(X, mask)\n",
    "    loss = criterion(out, y)\n",
    "\n",
    "    if torch.isnan(loss):\n",
    "        break\n",
    "        \n",
    "    losses.append(loss.item())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "535610fd-49e7-43bd-a722-8fd830b02b5f",
   "metadata": {},
   "source": [
    "out[21], X[21]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "589413e5-d15a-498d-8531-8bf0a205584a",
   "metadata": {},
   "source": [
    "X, mask, y = next(iter(train_dataloader))\n",
    "X, mask, y = next(iter(train_dataloader))\n",
    "X, mask, y = next(iter(train_dataloader))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "322f7e0b-70f4-401c-b825-9cc2eb5e81e2",
   "metadata": {},
   "source": [
    "X, mask, y = X.to(device), mask.to(device), y.to(device)\n",
    "out = model(X, mask)\n",
    "loss = criterion(out, y)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0645a6e3-a71e-4c93-b8d4-65ca2a574e25",
   "metadata": {},
   "source": [
    "math.isnan(losses[3])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "43a8817f-89bb-4a76-9490-e54ab75e0150",
   "metadata": {},
   "source": [
    "CLASSES = ['CWA', 'CWB', 'DCEP', 'DCEPS', 'DSCT', 'EA', 'EB', 'EW',\n",
    "           'HADS', 'M', 'ROT', 'RRAB', 'RRC', 'RRD', 'RVA', 'SR']\n",
    "train_dataset = VGDataset('/home/mariia/AstroML/data/asassn', 'v.csv', split='train', seq_len=200, scales='mean-mad', classes=CLASSES, max_samples=20000, aux=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d6580b-2829-437d-b72b-a33637f8ec99",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcabf22-ddd9-4e15-b426-89d786f67a00",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a265fd-7659-474b-ab17-dfa28051277d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a90bf-0cda-4a66-a949-81d61ddbef95",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ad952cd-01ed-4172-b8d4-f8922dc75324",
   "metadata": {},
   "source": [
    "i = 0\n",
    "train_dataset.df.iloc[i]['period'], train_dataset[i]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad34ac41-2a47-4d31-aed9-fc6b93179f06",
   "metadata": {},
   "source": [
    "train_dataset.df['period']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c781c02-59a2-486f-9c8f-054f2c5efac1",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2e7fba-0e14-4680-9fd2-4b97338c1388",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a965bcc-7fdc-4a09-b397-dfef2be0524e",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c00e08-8e9a-461f-ba51-a1b636aa1449",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "11b867ac-5ef4-49db-ac1e-0321a9e23f0f",
   "metadata": {},
   "source": [
    "for _ in range(10):\n",
    "    i = random.randint(0, len(train_dataset))\n",
    "    X = train_dataset.get_vlc(train_dataset.df.iloc[i]['name'])\n",
    "    period = train_dataset.df.iloc[i]['period']\n",
    "    \n",
    "    mean = X[:, 1].mean()\n",
    "    std = stats.median_abs_deviation(X[:, 1])\n",
    "    print(round(mean, 2), round(std, 2), round(np.log(mean), 2), round(np.log(std), 2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "de3d0c8a-040d-48e9-9ec7-2cdbc46579af",
   "metadata": {},
   "source": [
    "df = pd.read_csv('/home/mariia/AstroML/data/asassn/v.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c05f377e-4add-4b57-9204-6f8450cedd2f",
   "metadata": {},
   "source": [
    "pd.isna(df.iloc[3]['period'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f61f83-be84-456d-933e-937cc9982038",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb069b1-61b9-48e0-86eb-a5833cb2a631",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "973ec63c-0490-47d2-aa3b-99d449fa7b7c",
   "metadata": {},
   "source": [
    "log_mean = np.log(mean)\n",
    "log_std = np.log(std)\n",
    "log_period = np.log(period)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c976a0c2-e902-4681-8099-34fff6771d43",
   "metadata": {},
   "source": [
    "log_mean, log_std, log_period"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "174ec2bb-3abb-435a-b7ed-db425a00867f",
   "metadata": {},
   "source": [
    "X.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d2fe2d29-19b1-4436-a80c-4c3ecf2eb92a",
   "metadata": {},
   "source": [
    "aux = np.tile([log_mean, log_std, log_period], (X.shape[0], 1))\n",
    "aux.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "df1e96e9-2d8e-4e86-acc0-d339351d743c",
   "metadata": {},
   "source": [
    "features = np.concatenate((X, aux), axis=-1)\n",
    "features.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95349931-3c14-4e9b-9814-00bf595e1c19",
   "metadata": {},
   "source": [
    "features"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0258237-c037-486f-961b-e7c2c3e61d1d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4830ede8-cae6-486f-9f01-4a8c00d99636",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4932dce4-d57f-479d-a95b-e5a3de504855",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca2545b8-d18a-4006-913c-3c030453bc6f",
   "metadata": {},
   "source": [
    "g_data = VGDataset('/home/mariia/AstroML/data/asassn', 'g.csv', split='all')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8110474e-1d23-4201-86a1-110bfc2c6c81",
   "metadata": {},
   "source": [
    "g_data.df['target'].value_counts().sort_index()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b97929-db89-4a2b-aa87-fadf1466cb5d",
   "metadata": {},
   "source": [
    "CEPH, DSCT, ECL, LPV, RRAB, RRc/RRd, ROT"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cfa4f4-f20f-4ab8-9f54-390dd5d5661e",
   "metadata": {},
   "source": [
    "DSCT"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96b10d-956f-48c9-80aa-5564c52c0abe",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a5a07f-20ca-4422-9ebf-2e52b938ff6a",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d344d0c-5bcb-414d-aaee-80992cee8c09",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "78886b35-6485-40c2-8105-fea1910391fc",
   "metadata": {},
   "source": [
    "def preprocess_batch(batch, masks):\n",
    "    context_length = 200\n",
    "    lcs, classes = batch\n",
    "    lcs_mask, classes_mask = masks\n",
    "\n",
    "    # shape now [128, 1, 3, 759], make [128, 3, 759]\n",
    "    X = lcs[:, 0, :, :]\n",
    "\n",
    "    # change axises, shape now [128, 3, 759], make [128, 759, 3]\n",
    "    X = X.transpose(1, 2)\n",
    "\n",
    "    # since mask is the same for time flux and flux err we can make it 2D\n",
    "    mask = lcs_mask[:, 0, 0, :]\n",
    "\n",
    "    # context length 200, crop X and MASK if longer, pad if shorter\n",
    "    if X.shape[1] < context_length:\n",
    "        X_padding = (0, 0, 0, context_length - X.shape[1], 0, 0)\n",
    "        mask_padding = (0, context_length - X.shape[1])\n",
    "        X = F.pad(X, X_padding)\n",
    "        mask = F.pad(mask, mask_padding, value=True)\n",
    "    else:\n",
    "        X = X[:, :context_length, :]\n",
    "        mask = mask[:, :context_length]\n",
    "\n",
    "    # the last dimension is (time, flux, flux_err), sort it based on time\n",
    "    sort_indices = torch.argsort(X[:, :, 0], dim=1)\n",
    "    sorted_X = torch.zeros_like(X)\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "        sorted_X[i] = X[i, sort_indices[i]]\n",
    "\n",
    "    # rearange indexes for masks as well\n",
    "    sorted_mask = torch.zeros_like(mask)\n",
    "\n",
    "    for i in range(mask.shape[0]):\n",
    "        sorted_mask[i] = mask[i, sort_indices[i]]\n",
    "\n",
    "    # mask should be 1 for values that are observed and 0 for values that are missing\n",
    "    sorted_mask = 1 - sorted_mask.int()\n",
    "\n",
    "    # read scales\n",
    "    with open(os.path.join(data_root, 'scales.json'), 'r') as f:\n",
    "        scales = json.load(f)\n",
    "        mean, std = scales['v']['mean'], scales['v']['std']\n",
    "\n",
    "    # scale X\n",
    "    sorted_X[:, :, 1] = (sorted_X[:, :, 1] - mean) / std\n",
    "    sorted_X[:, :, 2] = sorted_X[:, :, 2] / std\n",
    "\n",
    "    # reshape classes to be 1D vector and convert from float to int\n",
    "    classes = classes[:, 0]\n",
    "    classes = classes.long()\n",
    "\n",
    "    return sorted_X, sorted_mask, classes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "c9631d7b-92ec-48e0-8d17-91090dada0df",
   "metadata": {},
   "source": [
    "import json\n",
    "import os\n",
    "from io import BytesIO\n",
    "import tarfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from util.parallelzipfile import ParallelZipFile as ZipFile\n",
    "from util.preprocess_data import clip_outliers\n",
    "\n",
    "\n",
    "class VGDataset(Dataset):\n",
    "    def __init__(self, data_root, vg_file, v_zip='asassnvarlc_vband_complete.zip', g_tar='g_band_lcs-001.tar',\n",
    "                 v_prefix='vardb_files', g_prefix='g_band_lcs', scales_file='scales.json',\n",
    "                 seq_len=200, split='train', min_samples=None, max_samples=None, classes=None, random_seed=42,\n",
    "                 phased=True, periodic=True, clip_outliers=True, verbose=True):\n",
    "        self.data_root = data_root\n",
    "        self.df = pd.read_csv(os.path.join(data_root, f'{vg_file}_{split}.csv'))\n",
    "        self.reader_v = ZipFile(os.path.join(data_root, v_zip))\n",
    "\n",
    "        self.v_prefix = v_prefix\n",
    "        self.g_prefix = g_prefix\n",
    "\n",
    "        with open(os.path.join(data_root, scales_file)) as f:\n",
    "            self.scales = json.load(f)\n",
    "\n",
    "        self.seq_len = seq_len\n",
    "        # self.split = split\n",
    "        self.min_samples = min_samples\n",
    "        self.max_samples = max_samples\n",
    "        self.classes = classes\n",
    "        self.phased = phased\n",
    "        self.periodic = periodic\n",
    "        self.clip_outliers = clip_outliers\n",
    "        self.verbose = verbose\n",
    "\n",
    "        self.random_seed = random_seed\n",
    "        np.random.seed(random_seed)\n",
    "\n",
    "        self._filter_classes()\n",
    "        self._filter_periodic()\n",
    "        self._limit_samples()\n",
    "        # self._split()\n",
    "        \n",
    "        self.id2target = {i: x for i, x in enumerate(sorted(self.df['target'].unique()))}\n",
    "        self.target2id = {v: k for k, v in self.id2target.items()}\n",
    "        self.num_classes = len(self.id2target)\n",
    "\n",
    "\n",
    "    # def _split(self):\n",
    "    #     unique_ids = self.df['id'].unique()\n",
    "    #     train_ids, temp_ids = train_test_split(unique_ids, test_size=0.2, random_state=self.random_seed)\n",
    "    #     val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=self.random_seed)\n",
    "\n",
    "    #     if self.split == 'train':\n",
    "    #         self.df = self.df[self.df['id'].isin(train_ids)]\n",
    "    #     elif self.split == 'val':\n",
    "    #         self.df = self.df[self.df['id'].isin(val_ids)]\n",
    "    #     elif self.split == 'test':\n",
    "    #         self.df = self.df[self.df['id'].isin(test_ids)]\n",
    "    #     else:\n",
    "    #         print('Split is not train, val, or test. Keeping the whole dataset')\n",
    "\n",
    "    #     if self.verbose:\n",
    "    #         print(f'{self.split} split is selected: {len(self.df)} objects left.')            \n",
    "\n",
    "    def _filter_classes(self):\n",
    "        if self.classes:\n",
    "            if self.verbose:\n",
    "                print(f'Leaving only classes: {self.classes}... ', end='')\n",
    "\n",
    "            self.df = self.df[self.df['target'].isin(self.classes)]\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f'{len(self.df)} objects left.')\n",
    "\n",
    "    def _filter_periodic(self):\n",
    "        if self.periodic:\n",
    "            if self.verbose:\n",
    "                print(f'Removing objects without periods... ', end='')\n",
    "\n",
    "            self.df = self.df[~self.df['period'].isna()]\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f'{len(self.df)} objects left.')\n",
    "\n",
    "    def _limit_samples(self):\n",
    "        if self.max_samples or self.min_samples:\n",
    "            if self.verbose:\n",
    "                print(\n",
    "                    f'Removing objects that have more than {self.max_samples} or less than {self.min_samples} samples... ',\n",
    "                    end='')\n",
    "\n",
    "            value_counts = self.df['target'].value_counts()\n",
    "\n",
    "            if self.min_samples:\n",
    "                classes_to_remove = value_counts[value_counts < self.min_samples].index\n",
    "                self.df = self.df[~self.df['target'].isin(classes_to_remove)]\n",
    "\n",
    "            if self.max_samples:\n",
    "                classes_to_limit = value_counts[value_counts > self.max_samples].index\n",
    "                for class_type in classes_to_limit:\n",
    "                    class_indices = self.df[self.df['target'] == class_type].index\n",
    "                    indices_to_keep = np.random.choice(class_indices, size=self.max_samples, replace=False)\n",
    "                    self.df = self.df.drop(index=set(class_indices) - set(indices_to_keep))\n",
    "\n",
    "            if self.verbose:\n",
    "                print(f'{len(self.df)} objects left.')\n",
    "\n",
    "    def get_vlc(self, file_name):\n",
    "        csv = BytesIO()\n",
    "        data_path = f'{self.v_prefix}/{file_name}.dat'\n",
    "\n",
    "        csv.write(self.reader_v.read(data_path))\n",
    "        csv.seek(0)\n",
    "\n",
    "        lc = pd.read_csv(csv, sep='\\s+', skiprows=2, names=['HJD', 'MAG', 'MAG_ERR', 'FLUX', 'FLUX_ERR'],\n",
    "                         dtype={'HJD': float, 'MAG': float, 'MAG_ERR': float, 'FLUX': float, 'FLUX_ERR': float})\n",
    "\n",
    "        return lc[['HJD', 'FLUX', 'FLUX_ERR']].values\n",
    "\n",
    "    def get_glc(self, file_name):\n",
    "        lc = pd.read_csv(os.path.join(self.data_root, self.g_prefix, f'{file_name}.dat'), sep='\\s+', skiprows=2,\n",
    "                         names=['HJD', 'camera', 'mag', 'mag_err', 'flux', 'flux_err', 'FWHM', 'IMAGE'],\n",
    "                         dtype={'HJD': float, 'camera': 'object', 'mag': 'object', 'mag_err': 'object',\n",
    "                                'flux': float, 'flux_err': float, 'FWHM': 'object', 'IMAGE': 'object'})\n",
    "\n",
    "        return lc[['HJD', 'flux', 'flux_err']].values\n",
    "\n",
    "    def preprocess(self, X, period, band):\n",
    "        # 3 clip outliers\n",
    "        t, y, y_err = X[:, 0], X[:, 1], X[:, 2]\n",
    "        if self.clip_outliers and len(t) > 20:\n",
    "            t, y, y_err, _, _, _, _, _ = clip_outliers(t, y, y_err, measurements_in_flux_units=True,\n",
    "                                                       initial_clip=(20, 5), clean_only=True)\n",
    "        X = np.vstack((t, y, y_err)).T\n",
    "        \n",
    "        # 1 phase\n",
    "        if self.phased:\n",
    "            X = np.vstack(((X[:, 0] % period) / period, X[:, 1], X[:, 2])).T\n",
    "\n",
    "        # 5 trim/pad and create mask\n",
    "        mask = np.ones(self.seq_len)\n",
    "\n",
    "        if X.shape[0] > self.seq_len:\n",
    "            X = X[:self.seq_len, :]\n",
    "        else:\n",
    "            mask[X.shape[0]:] = 0\n",
    "            X = np.pad(X, ((0, self.seq_len - X.shape[0]), (0, 0)), 'constant', constant_values=(0,))\n",
    "        \n",
    "        # 4 normalize\n",
    "        mean, std = self.scales[band]['mean'], self.scales[band]['std']\n",
    "        X[:, 1] = (X[:, 1] - mean) / std\n",
    "        X[:, 2] = X[:, 2] / std\n",
    "\n",
    "        # 2 sort based on HJD\n",
    "        sorted_indices = np.argsort(X[:, 0])\n",
    "        X = X[sorted_indices]\n",
    "        mask = mask[sorted_indices]\n",
    "\n",
    "        # 6 convert X and mask from float64 to float32\n",
    "        X = X.astype(np.float32)\n",
    "        mask = mask.astype(np.float32)\n",
    "\n",
    "        # return X[:, 1:], mask\n",
    "        return X, mask\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        el = self.df.iloc[idx]\n",
    "\n",
    "        X = self.get_vlc(el['name']) if el['band'] == 'v' else self.get_glc(el['name'])\n",
    "        X, mask = self.preprocess(X, el['period'], el['band'])\n",
    "        y = self.target2id[el['target']]\n",
    "\n",
    "        return X, mask, y"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ccb7c64-91d3-4357-992c-9bd2d9e5f836",
   "metadata": {},
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2106b274-aab2-4551-bad0-688463df497d",
   "metadata": {},
   "source": [
    "data_root = '/home/mariia/AstroML/data/asassn'\n",
    "classes = ['CWA', 'CWB', 'DCEP', 'DCEPS', 'DSCT', 'EA', 'EB', 'EW', 'HADS', 'M', 'ROT', 'RRAB', 'RRC', 'RRD', 'RVA', 'SR']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b6e3f430-bf4c-48dc-bd5d-7973d7251ad5",
   "metadata": {},
   "source": [
    "df1 = pd.read_csv('/home/mariia/AstroML/data/asassn/asassn_catalog_full.csv')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "cb2c9aa1-28ec-40a2-b91e-55b71b39c477",
   "metadata": {},
   "source": [
    "df1 = df1[~df1['edr3_source_id'].isna()]\n",
    "df1 = df1.drop_duplicates(subset='edr3_source_id')\n",
    "df1 = df1[df1['variable_type'].isin(classes)]\n",
    "df1 = df1[df1['periodic']]\n",
    "\n",
    "max_samples = 20000\n",
    "value_counts = df1['variable_type'].value_counts()\n",
    "classes_to_limit = value_counts[value_counts > max_samples].index\n",
    "\n",
    "for class_type in classes_to_limit:\n",
    "    class_indices = df1[df1['variable_type'] == class_type].index\n",
    "    indices_to_keep = np.random.choice(class_indices, size=max_samples, replace=False)\n",
    "    df1 = df1.drop(index=set(class_indices) - set(indices_to_keep))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "c342b1ab-6a80-4025-8a04-a061ed92648b",
   "metadata": {},
   "source": [
    "len(df1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1ff509c0-1d20-496a-aabd-f8b24363b0ad",
   "metadata": {},
   "source": [
    "df1.to_csv('/home/mariia/AstroML/data/asassn/asassn_catalog_short.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "fb897710-e802-44a4-ae12-543ea2e27523",
   "metadata": {},
   "source": [
    "df2 = df1[['variable_type', 'period', 'asassn_name', 'edr3_source_id']].copy()\n",
    "df2['band'] = 'v'\n",
    "df2.columns = ['target', 'period', 'name', 'id', 'band']\n",
    "df2['name'] = df2['name'].apply(lambda x: x.replace(' ', ''))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "c7f6bf83-f1c8-4539-9a6b-0cc528619001",
   "metadata": {},
   "source": [
    "df2.to_csv('/home/mariia/AstroML/data/asassn/asassn_catalog_short_newdataset.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "4b06665a-e82d-4c27-b59a-4a251b9d490c",
   "metadata": {},
   "source": [
    "len(df2)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a68aa5c3-6bb1-4efa-b5e5-56587f6d7c3a",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53bb0ce-21a0-4c44-8e6e-ea4f64dac106",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "9e033aa7-0ab2-47b5-b96d-ddcebf283d79",
   "metadata": {},
   "source": [
    "datapath = Path(data_root)\n",
    "ds1 = ASASSNVarStarDataset(datapath, mode='train', max_samples=20000, verbose=True, only_periodic=True, recalc_period=False, prime=True, use_bands=['v'], only_sources_with_spectra=False, \n",
    "                           return_phased=True, fill_value=0, use_classes=classes)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "63e6cb66-a118-47a8-a820-fb5d2b505e6c",
   "metadata": {},
   "source": [
    "df_train = ds1.df[['variable_type', 'period', 'asassn_name', 'edr3_source_id']].copy()\n",
    "df_train['band'] = 'v'\n",
    "df_train.columns = ['target', 'period', 'name', 'id', 'band']\n",
    "df_train['name'] = df_train['name'].apply(lambda x: x.replace(' ', ''))\n",
    "df_train.to_csv('/home/mariia/AstroML/data/asassn/catalog_short_train.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "fff92e14-8370-4871-81ba-bf31ba958758",
   "metadata": {},
   "source": [
    "ds_val = ASASSNVarStarDataset(datapath, mode='val', max_samples=20000, verbose=True, only_periodic=True, recalc_period=False, prime=True, use_bands=['v'], only_sources_with_spectra=False, \n",
    "                           return_phased=True, fill_value=0, use_classes=classes)\n",
    "df_val = ds_val.df[['variable_type', 'period', 'asassn_name', 'edr3_source_id']].copy()\n",
    "df_val['band'] = 'v'\n",
    "df_val.columns = ['target', 'period', 'name', 'id', 'band']\n",
    "df_val['name'] = df_val['name'].apply(lambda x: x.replace(' ', ''))\n",
    "df_val.to_csv('/home/mariia/AstroML/data/asassn/catalog_short_val.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "ba8127e4-cc9e-47cb-b93f-02073e7ea568",
   "metadata": {},
   "source": [
    "ds_test = ASASSNVarStarDataset(datapath, mode='val', max_samples=20000, verbose=True, only_periodic=True, recalc_period=False, prime=True, use_bands=['v'], only_sources_with_spectra=False, \n",
    "                               return_phased=True, fill_value=0, use_classes=classes)\n",
    "df_test = ds_val.df[['variable_type', 'period', 'asassn_name', 'edr3_source_id']].copy()\n",
    "df_test['band'] = 'v'\n",
    "df_test.columns = ['target', 'period', 'name', 'id', 'band']\n",
    "df_test['name'] = df_test['name'].apply(lambda x: x.replace(' ', ''))\n",
    "df_test.to_csv('/home/mariia/AstroML/data/asassn/catalog_short_test.csv', index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67973a6e-e738-49d4-b38d-1ccbd9e3d810",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de86f7c-92f6-4f56-9ce2-e3dc0f3a90a2",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5180fef3-a7c9-441c-b590-54219222aa05",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd427bd-22f0-4201-b261-a22ad01848da",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7db2f114-13c6-46fa-870e-9991d81db20b",
   "metadata": {},
   "source": [
    "ds2 = VGDataset(data_root, 'catalog_short', split='train', seq_len=200, max_samples=20000, phased=True, periodic=True, classes=classes)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "b0f7cf3f-92b7-4f42-810a-778240873b9d",
   "metadata": {},
   "source": [
    "ds2[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2a1982-36f3-4c50-abe6-be88663b625d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "41cc5383-b459-4e8b-a887-2eeaf4884110",
   "metadata": {},
   "source": [
    "ds1.df[['variable_type', 'period', 'asassn_name', 'edr3_source_id']]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "f40f3edd-6179-474a-a32a-c31898d75de5",
   "metadata": {},
   "source": [
    "ds2.df[~ds2.df['id'].isin(ds1.df['edr3_source_id'])]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2ace76-c3d1-4d10-b0d2-ae40e2fc84ae",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde15474-473e-4346-a275-2aaf02b07fa9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7a2a4d-76d1-408b-89df-ecf080ffd729",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f29e627-1f6a-4928-8c99-af434b255291",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0a604a81-0eb2-4393-ad81-67bfda53dd9c",
   "metadata": {},
   "source": [
    "ds1.df = df1.reset_index().copy()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d0676564-c863-4c3d-b5f5-fed48799c775",
   "metadata": {},
   "source": [
    "no_spectra_data_keys = ['lcs', 'classes']\n",
    "no_spectra_collate_fn = partial(collate_fn, data_keys=no_spectra_data_keys, fill_value=0)\n",
    "\n",
    "dl1 = DataLoader(ds1, batch_size=16, shuffle=False, collate_fn=no_spectra_collate_fn)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "a3a2c09b-1894-46ec-8f3f-12018136ab63",
   "metadata": {},
   "source": [
    "b1, m1 = next(iter(dl1))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "15caa1ea-4e4f-48de-8d69-17967e507913",
   "metadata": {},
   "source": [
    "X1, mask1, y1 = preprocess_batch(b1, m1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "9614c5de-3e83-4c72-8f21-309abeb8f13a",
   "metadata": {},
   "source": [
    "dl2 = DataLoader(ds2, batch_size=16, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "bf640ce8-2cf9-4056-9c94-fb96eea7a02a",
   "metadata": {},
   "source": [
    "X2, mask2, y2 = next(iter(dl2))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "f781eae8-f4be-4251-96c4-9b5c5089eb07",
   "metadata": {},
   "source": [
    "X1.shape, X2.shape, mask1.shape, mask2.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "a503d363-0f4c-4fce-b652-ab00d3f2e29c",
   "metadata": {},
   "source": [
    "num_plots = X1.shape[0]\n",
    "fig, axes = plt.subplots(num_plots, 4, figsize=(10, num_plots * 2))\n",
    "\n",
    "for i in range(num_plots):\n",
    "    axes[i, 0].plot(X1[i, :, 1])\n",
    "    axes[i, 0].set_title(f'X1[{i}, :, 1]')\n",
    "    \n",
    "    axes[i, 1].plot(X2[i, :, 1])\n",
    "    axes[i, 1].set_title(f'X2[{i}, :, 1]')\n",
    "\n",
    "    axes[i, 2].plot(mask1[i])\n",
    "    axes[i, 3].plot(mask2[i])\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95ed00b-e371-412b-a749-cabaf3dba63e",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae68e01e-782a-4d4a-8ef6-547908bad975",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0b405e-0d41-4ef4-b6f7-8d5c9f66b71f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb73a8b3-97ba-4329-91ba-16cf87c64bf5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5abacab-6cb3-401e-acba-cd5be07e38f7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c158b0ac-4434-4374-8c7d-b9a8fa2cc256",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7506ed5a-7c37-4525-a5fc-12504cd3f379",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3910b7c4-a97d-412e-96e4-d8558b1d2d59",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6c606-ab3d-4f92-b647-3a8cea947a6c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf211c95-85e8-4656-8837-7d6b770bb9e2",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1ea1e-2356-46ba-93c7-feb0658408d5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba52acad-23d0-4dbc-b6ac-39d796b1a85d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7dedebb0-77c9-4f47-befb-e5cfb9c25ce5",
   "metadata": {},
   "source": [
    "ds1.df = ds1.df.reset_index(drop=True)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "20087287-66b3-4ee1-a0f5-eb3a9959b708",
   "metadata": {},
   "source": [
    "ds1.df[ds1.df['edr3_source_id'].isin(inds)].index"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "75dc9f4e-f7f5-432a-a7b7-2ff49480b36f",
   "metadata": {},
   "source": [
    "len(ds1.df), len(ds2.df)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "dc76b6b8-d38d-4fae-8000-d9ccc4391b7d",
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(2, 5, figsize=(15, 6))  # 2 rows and 5 columns to plot 10 images\n",
    "source_ids = list(ds1.df[ds1.df['edr3_source_id'].isin(ds2.df['id'])]['edr3_source_id'])\n",
    "\n",
    "for i in range(5):\n",
    "    source_id = source_ids[i]\n",
    "    lc1 = ds1[ds1.df[ds1.df['edr3_source_id'] == source_id].index[0]]['lcs'][0][0]\n",
    "    lc2, _, _ = ds2[ds2.df[ds2.df['id'] == source_id].index[0]]\n",
    "    \n",
    "    axs[0, i].plot(lc1[:, 0], lc1[:, 1], '.')\n",
    "    axs[1, i].plot(lc2[:, 0], lc2[:, 1], '.')\n",
    "\n",
    "    axs[0, i].set_title('Old Dataset')\n",
    "    axs[1, i].set_title('New Dataset')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5d555d0e-2569-43a8-869b-44815b3633b3",
   "metadata": {},
   "source": [
    "lc1 = ds1.get_light_curves(ds1.df[ds1.df['edr3_source_id'] == 'EDR3 3526846175029144576'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "80b33b87-c71c-44e3-913a-dd0222523f86",
   "metadata": {},
   "source": [
    "lc2, mask, y = ds2[730]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "f8d592ae-3a01-4087-94ce-d08c5d56f2dc",
   "metadata": {},
   "source": [
    "plt.plot(lc1[0][0][:, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8636b942-1ed1-4488-9d28-c07b519c49a5",
   "metadata": {},
   "source": [
    "plt.plot(lc2[:, 0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9fcab6d-d98f-455d-8fe5-a974ab1a2adf",
   "metadata": {},
   "source": [
    "plt.plot(lc1[0][0][:, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "eff4ba64-50a0-4096-b88d-3cad402891f0",
   "metadata": {},
   "source": [
    "plt.plot(lc2[:, 0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ebc7fa-679a-4e1c-9028-a1e0876e348a",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
