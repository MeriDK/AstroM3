{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4898eedf-33b0-42cb-87f4-69e8a43d50e4",
   "metadata": {},
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b5a4e4-f87b-488f-822c-cf59cd1e0b35",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction, TimeSeriesTransformerModel \n",
    "from transformers.models.time_series_transformer.modeling_time_series_transformer import TimeSeriesTransformerEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from scipy import stats\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pathlib import Path\n",
    "from core.multimodal.dataset import collate_fn, ASASSNVarStarDataset\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from astropy.io import fits\n",
    "\n",
    "from core.spectra.dataset import SpectraVDataset\n",
    "from core.spectra.model import GalSpecNet"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6dd5ae41-c586-44ca-80dc-650bd391cab9",
   "metadata": {},
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f8b693e-460b-4248-ad4d-363bf10075b4",
   "metadata": {},
   "source": [
    "data_root = '/home/mariia/AstroML/data/asassn'\n",
    "lamost_spec_file='Spectra/lamost_spec.csv'\n",
    "lamost_spec_dir='Spectra/v2'\n",
    "# v_file = 'asassn_catalog_full.csv'\n",
    "v_file = 'v.csv'\n",
    "spectra_v_file = 'spectra_v_merged.csv'"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a78d2b4-5530-4623-b9fa-a9c0fcbe79b6",
   "metadata": {},
   "source": [
    "CLASSES = ['CWA', 'CWB', 'DCEP', 'DCEPS', 'DSCT', 'EA', 'EB', 'EW',\n",
    "           'HADS', 'M', 'ROT', 'RRAB', 'RRC', 'RRD', 'RVA', 'SR']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c87160e4-89dd-4101-8398-d8fe6c9fae4c",
   "metadata": {},
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for fluxes, label in tqdm(train_dataloader):\n",
    "        fluxes, label = fluxes.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(fluxes)\n",
    "        loss = criterion(logits, label)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "        correct_predictions = (predicted_labels == label).sum().item()\n",
    "\n",
    "        total_correct_predictions += correct_predictions\n",
    "        total_predictions += label.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return sum(total_loss) / len(total_loss), total_correct_predictions / total_predictions\n",
    "    \n",
    "def val_epoch():\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for fluxes, label in tqdm(val_dataloader):\n",
    "            fluxes, label = fluxes.to(device), label.to(device)\n",
    "\n",
    "            logits = model(fluxes)\n",
    "            loss = criterion(logits, label)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "            _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "            correct_predictions = (predicted_labels == label).sum().item()\n",
    "    \n",
    "            total_correct_predictions += correct_predictions\n",
    "            total_predictions += label.size(0)\n",
    "\n",
    "    return sum(total_loss) / len(total_loss), total_correct_predictions / total_predictions"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "829664d4-46b4-44e8-aba4-0ca047f310fc",
   "metadata": {},
   "source": [
    "class SpectraVDataset(Dataset):\n",
    "    def __init__(self, data_root, lamost_spec_dir, spectra_v_file, split='train', classes=None, z_corr=False):\n",
    "        self.data_root = data_root\n",
    "        self.lamost_spec_dir = os.path.join(data_root, lamost_spec_dir)\n",
    "        self.spectra_v_file = os.path.join(data_root, spectra_v_file)\n",
    "        self.split = split\n",
    "        self.z_corr = z_corr\n",
    "\n",
    "        self.df = pd.read_csv(self.spectra_v_file)\n",
    "        self.df = self.df[['edr3_source_id', 'variable_type', 'spec_filename']]\n",
    "\n",
    "        if classes:\n",
    "            self.df = self.df[self.df['variable_type'].isin(classes)]\n",
    "\n",
    "        self._split()\n",
    "\n",
    "        self.id2target = {i: x for i, x in enumerate(sorted(self.df['variable_type'].unique()))}\n",
    "        self.target2id = {v: k for k, v in self.id2target.items()}\n",
    "        self.num_classes = len(self.id2target)\n",
    "\n",
    "    def _split(self):\n",
    "        total_size = len(self.df)\n",
    "        train_size = int(total_size * 0.7)\n",
    "        val_size = int(total_size * 0.15)\n",
    "\n",
    "        shuffled_df = self.df.sample(frac=1, random_state=42)\n",
    "\n",
    "        if self.split == 'train':\n",
    "            self.df = shuffled_df[:train_size]\n",
    "        elif self.split == 'val':\n",
    "            self.df = shuffled_df[train_size:train_size + val_size]\n",
    "        elif self.split == 'test':\n",
    "            self.df = shuffled_df[train_size + val_size:]\n",
    "        else:\n",
    "            self.df = shuffled_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        el = self.df.iloc[idx]\n",
    "        variable_type, spec_filename = el['variable_type'], el['spec_filename']\n",
    "        label = self.target2id[variable_type]\n",
    "\n",
    "        # read spectra\n",
    "        spectra = self.readLRSFits(os.path.join(self.lamost_spec_dir, spec_filename))\n",
    "        original_wavelengths, fluxes = spectra[:, 0], spectra[:, 1]\n",
    "\n",
    "        # interpolate\n",
    "        wavelengths = np.arange(3850, 9000, 2)\n",
    "        fluxes = np.interp(wavelengths, original_wavelengths, fluxes)\n",
    "\n",
    "        # normalize\n",
    "        # fluxes = (fluxes - fluxes.mean()) / fluxes.std()\n",
    "        N = np.sum(fluxes ** 2)\n",
    "        fluxes = fluxes / np.sqrt(N)\n",
    "\n",
    "        # reshape so batches are [N, 1, (9000-3850)//2]\n",
    "        fluxes = fluxes.reshape(1, -1).astype(np.float32)\n",
    "\n",
    "        return fluxes, label\n",
    "\n",
    "    def readLRSFits(self, filename):\n",
    "        \"\"\"\n",
    "        Read LAMOST fits file\n",
    "          adapted from https://github.com/fandongwei/pylamost\n",
    "\n",
    "        Parameters:\n",
    "        -----------\n",
    "        filename: str\n",
    "          name of the fits file\n",
    "        z_corr: bool.\n",
    "          if True, correct for measured radial velocity of star\n",
    "\n",
    "        Returns:\n",
    "        --------\n",
    "        spec: numpy array\n",
    "          wavelength, flux, inverse variance\n",
    "        \"\"\"\n",
    "\n",
    "        hdulist = fits.open(filename)\n",
    "        len_list = len(hdulist)\n",
    "\n",
    "        if len_list == 1:\n",
    "            head = hdulist[0].header\n",
    "            scidata = hdulist[0].data\n",
    "            coeff0 = head['COEFF0']\n",
    "            coeff1 = head['COEFF1']\n",
    "            pixel_num = head['NAXIS1']\n",
    "            specflux = scidata[0,]\n",
    "            ivar = scidata[1,]\n",
    "            wavelength = np.linspace(0, pixel_num - 1, pixel_num)\n",
    "            wavelength = np.power(10, (coeff0 + wavelength * coeff1))\n",
    "            hdulist.close()\n",
    "        elif len_list == 2:\n",
    "            head = hdulist[0].header\n",
    "            scidata = hdulist[1].data\n",
    "            wavelength = scidata[0][2]\n",
    "            ivar = scidata[0][1]\n",
    "            specflux = scidata[0][0]\n",
    "        else:\n",
    "            raise ValueError(f'Wrong number of fits files. {len_list} should be 1 or 2')\n",
    "\n",
    "        if self.z_corr:\n",
    "            try:\n",
    "                # correct for radial velocity of star\n",
    "                redshift = head['Z']\n",
    "            except Exception as e:\n",
    "                print(e, 'Setting redshift to zero')\n",
    "                redshift = 0.0\n",
    "\n",
    "            wavelength = wavelength - redshift * wavelength\n",
    "\n",
    "        return np.vstack((wavelength, specflux, ivar)).T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f360b9b6-7bf1-41c8-93ce-418e4c0be272",
   "metadata": {},
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=5, stride=3, short_cut=True):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        \n",
    "        self.short_cut = short_cut\n",
    "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=1, padding=2)\n",
    "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
    "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=kernel_size, stride=stride)\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.pool = nn.MaxPool1d(kernel_size=kernel_size, stride=1, padding=2)\n",
    "        \n",
    "        if self.short_cut:\n",
    "            self.shortcut_conv = nn.Conv1d(in_channels, out_channels, kernel_size=kernel_size, stride=stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        \n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.pool(out)\n",
    "        \n",
    "        if self.short_cut:\n",
    "            identity = self.shortcut_conv(identity)\n",
    "        \n",
    "        out += identity\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes, dropout=0.5):\n",
    "        super(ResNet, self).__init__()\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            ResNetBlock(1, 16),\n",
    "            ResNetBlock(16, 32),\n",
    "            ResNetBlock(32, 64),\n",
    "            # ResNetBlock(64, 128),\n",
    "            # ResNetBlock(128, 256),\n",
    "            # ResNetBlock(256, 512)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(6016, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19d11f41-7b60-40bc-84cd-436eefb07a76",
   "metadata": {},
   "source": [
    "\n",
    "train_dataset = SpectraVDataset(data_root, lamost_spec_dir, spectra_v_file, classes=None, split='train')\n",
    "val_dataset = SpectraVDataset(data_root, lamost_spec_dir, spectra_v_file, classes=None, split='val')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "31c282e9-cf69-489b-ad4c-f138aa61dc34",
   "metadata": {},
   "source": [
    "train_dataset.df['variable_type'].value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2977ca08-eb49-41d8-9380-d49cb698f051",
   "metadata": {},
   "source": [
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)\n",
    "\n",
    "model = ResNet(train_dataset.num_classes)\n",
    "model = model.to(device)\n",
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a6fce88a-0d48-40c9-9ce8-f2ccecfb0f9d",
   "metadata": {},
   "source": [
    "for i in range(20):\n",
    "    print(f'Epoch {i}')\n",
    "    \n",
    "    train_loss, train_acc = train_epoch()\n",
    "    print(f'Train Loss: {round(train_loss, 3)} Acc: {round(train_acc, 2)}')\n",
    "    \n",
    "    val_loss, val_acc = val_epoch()\n",
    "    print(f'Val Loss: {round(val_loss, 3)} Acc: {round(val_acc, 2)}')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4f04a1-c30a-4158-8765-a37b433ca8cd",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a4d728-1a28-4a4c-9033-213ffe9d8aae",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320490f0-0bd5-4991-a6a3-fcdf843fc1c6",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1ec996-fa65-48bb-83fe-971f88849b17",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13cf110-5eef-4348-bcd0-0482f5fa70b9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f93b7-3ce8-4d3c-9099-e89318bfdb42",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dd1d110-25c6-48bc-babe-e88eb1966e46",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f099c7c8-440a-4e3b-966d-29d45825c335",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92407e0-7a03-47b8-b0c1-2f393c82b3ff",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139eb15e-555b-41ae-afd4-49e6bb216265",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffea5a2-7c4d-4e2b-a726-8b01bdc5dc28",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1df22ae-36d7-4334-85b6-af249ed9aba3",
   "metadata": {},
   "source": [
    "dataset = SpectraVDataset(data_root, lamost_spec_dir, spectra_v_file, classes=CLASSES, split='all')\n",
    "dataloader = DataLoader(dataset, batch_size=16, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "81b85991-24ae-458c-9f15-857515f4100c",
   "metadata": {},
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    X, y = dataset[i]\n",
    "    \n",
    "    if X.std() < 0.01:\n",
    "        print(i)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f940ed30-c30d-41e3-b9f9-223ab2f8e08e",
   "metadata": {},
   "source": [
    "plt.plot(dataset[7984][0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f12ab696-0aea-4f4f-ad37-d4439ee1a59c",
   "metadata": {},
   "source": [
    "stats.median_abs_deviation(dataset[7984][0])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b323241-0021-4af8-92ce-abb45048c044",
   "metadata": {},
   "source": [
    "dataset[873][0].std()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab511fd-46cc-449e-bd84-94df253f5bcb",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbb90bc1-4d7a-4370-ae35-e6c5b7e0af4f",
   "metadata": {},
   "source": [
    "model = GalSpecNet(dataset.num_classes)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f83c56e2-d443-4bb6-9dce-4c78a20ec783",
   "metadata": {},
   "source": [
    "X, y = next(iter(dataloader))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f0d617b7-0890-49ec-9f4d-779229ec6f0b",
   "metadata": {},
   "source": [
    "for X, y in tqdm(dataloader):\n",
    "    try:\n",
    "        out = model(X)\n",
    "        loss = criterion(out, y)\n",
    "    except:\n",
    "        break"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634abf40-f291-4847-884a-b06cdcb389b7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8411c307-ed63-4452-956b-a5c0fa15099b",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1ce08a-51c3-4714-bd11-35f77a033f90",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ccf1a6f-6f4b-4a11-9cc2-c0060643f9c9",
   "metadata": {},
   "source": [
    "for i in tqdm(range(len(dataset))):\n",
    "    try:\n",
    "        dataset[i]\n",
    "    except:\n",
    "        print(i)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ce91603-bcb7-4c5b-832c-49ebe1850029",
   "metadata": {},
   "source": [
    "dataset[3]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd4ee3a-a652-415a-bdfa-18ec109c3493",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5ebe77-db58-47d3-998e-c44bcbe1315a",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca68bbd0-cde5-45cd-96f7-715aa8071ad8",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "859b2505-1e3c-4eef-b1b9-11b9f18916d8",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "26387ee3-8426-4727-a77e-db23a1c14097",
   "metadata": {},
   "source": [
    "spec_df = pd.read_csv(os.path.join(data_root, lamost_spec_file), index_col=0)\n",
    "v_df = pd.read_csv(os.path.join(data_root, v_file))\n",
    "\n",
    "v_df = v_df.drop_duplicates(subset=['edr3_source_id'])\n",
    "spec_df = spec_df.drop_duplicates(subset=['edr3_source_id'])\n",
    "\n",
    "df = pd.merge(v_df, spec_df, on='edr3_source_id', how='inner')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "d40ca609-f54d-4f2d-b514-22ca8a1c2d80",
   "metadata": {},
   "source": [
    "source_ids = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    el = df.iloc[i]\n",
    "    path = el['spec_filename']\n",
    "    \n",
    "    if not os.path.exists(os.path.join(data_root, lamost_spec_dir, path)):\n",
    "        source_ids.append(el['edr3_source_id'])\n",
    "        print(i, el['edr3_source_id'])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "775e1fff-43a4-44eb-9985-5591e379d341",
   "metadata": {},
   "source": [
    "df = df[~df['edr3_source_id'].isin(source_ids)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "2ee18827-d8c1-4519-baef-d3cb36784334",
   "metadata": {},
   "source": [
    "weird_sources = ['EDR3 3714273187707121920', 'EDR3 3222213829875076096', 'EDR3 601653935246445696']\n",
    "df = df[~df['edr3_source_id'].isin(weird_sources)]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "8bc1ff09-458c-4b97-99cd-78deaefca40e",
   "metadata": {},
   "source": [
    "df.to_csv(os.path.join(data_root, spectra_v_file), index=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "8f904189-7d32-4046-9a4e-94005e01862c",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "spectra = train_dataset2[3609]\n",
    "print(train_dataset2.df.iloc[3609]['edr3_source_id'])\n",
    "plt.plot(spectra[:, 0], spectra[:, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "ba78ddde-26dc-46d7-89c1-51464123b16d",
   "metadata": {},
   "source": [
    "spectra = train_dataset2[3772]\n",
    "print(train_dataset2.df.iloc[3772]['edr3_source_id'])\n",
    "plt.plot(spectra[:, 0], spectra[:, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "d7c2619f-dff2-486b-8619-6252f787d1b2",
   "metadata": {},
   "source": [
    "spectra = train_dataset2[8568]\n",
    "print(train_dataset2.df.iloc[8568]['edr3_source_id'])\n",
    "plt.plot(spectra[:, 0], spectra[:, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "7e6e2b79-7083-40b7-af4e-559ef5acf3e8",
   "metadata": {},
   "source": [
    "spectra = train_dataset2[8569]\n",
    "plt.plot(spectra[:, 0], spectra[:, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bde619c8-f005-4ffd-bbe9-90f9e1faf9b5",
   "metadata": {},
   "source": [
    "class SpectraVDataset(Dataset):\n",
    "    def __init__(self, data_root, lamost_spec_dir, spectra_v_file, split='train', classes=None, z_corr=False):\n",
    "        self.data_root = data_root\n",
    "        self.lamost_spec_dir = os.path.join(data_root, lamost_spec_dir)\n",
    "        self.spectra_v_file = os.path.join(data_root, spectra_v_file)\n",
    "        self.split = split\n",
    "        self.z_corr = z_corr\n",
    "\n",
    "        self.df = pd.read_csv(self.spectra_v_file)\n",
    "        self.df = self.df[['edr3_source_id', 'variable_type', 'spec_filename']]\n",
    "\n",
    "        if classes:\n",
    "            self.df = self.df[self.df['variable_type'].isin(classes)]\n",
    "            \n",
    "        self._split()\n",
    "\n",
    "        self.id2target = {i: x for i, x in enumerate(sorted(self.df['variable_type'].unique()))}\n",
    "        self.target2id = {v: k for k, v in self.id2target.items()}\n",
    "        self.num_classes = len(self.id2target)\n",
    "\n",
    "    def _split(self):\n",
    "        total_size = len(self.df)\n",
    "        train_size = int(total_size * 0.7)\n",
    "        val_size = int(total_size * 0.15)\n",
    "\n",
    "        shuffled_df = self.df.sample(frac=1, random_state=42)\n",
    "\n",
    "        if self.split == 'train':\n",
    "            self.df = shuffled_df[:train_size]\n",
    "        elif self.split == 'val':\n",
    "            self.df = shuffled_df[train_size:train_size + val_size]\n",
    "        elif self.split == 'test':\n",
    "            self.df = shuffled_df[train_size + val_size:]\n",
    "        else:\n",
    "            self.df = shuffled_df\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        el = self.df.iloc[idx]\n",
    "        variable_type, spec_filename = el['variable_type'], el['spec_filename']\n",
    "        label = self.target2id[variable_type]\n",
    "\n",
    "        # read spectra\n",
    "        spectra = self.readLRSFits(os.path.join(self.lamost_spec_dir, spec_filename))\n",
    "        original_wavelengths, fluxes = spectra[:, 0], spectra[:, 1]\n",
    "        \n",
    "        # interpolate\n",
    "        wavelengths = np.arange(3850, 9000, 2)\n",
    "        fluxes = np.interp(wavelengths, original_wavelengths, fluxes)\n",
    "\n",
    "        # normalize\n",
    "        # fluxes = fluxes / fluxes.mean()\n",
    "        # fluxes = (fluxes - fluxes.min()) / (fluxes.max() - fluxes.min())\n",
    "        mean = fluxes.mean()\n",
    "        mad = stats.median_abs_deviation(fluxes)\n",
    "        fluxes = (fluxes - mean) / mad\n",
    "\n",
    "        # reshape so batches are [N, 1, (9000-3850)//2]\n",
    "        fluxes = fluxes.reshape(1, -1).astype(np.float32)\n",
    "\n",
    "        return fluxes, label\n",
    "\n",
    "        \n",
    "    def readLRSFits(self, filename):\n",
    "        \"\"\"\n",
    "        Read LAMOST fits file\n",
    "          adapted from https://github.com/fandongwei/pylamost\n",
    "    \n",
    "        Parameters:\n",
    "        -----------\n",
    "        filename: str\n",
    "          name of the fits file\n",
    "        z_corr: bool.\n",
    "          if True, correct for measured radial velocity of star\n",
    "    \n",
    "        Returns:\n",
    "        --------\n",
    "        spec: numpy array\n",
    "          wavelength, flux, inverse variance\n",
    "        \"\"\"\n",
    "    \n",
    "        hdulist = fits.open(filename)\n",
    "        len_list = len(hdulist)\n",
    "        \n",
    "        if len_list == 1:\n",
    "            head = hdulist[0].header\n",
    "            scidata = hdulist[0].data\n",
    "            coeff0 = head['COEFF0']\n",
    "            coeff1 = head['COEFF1']\n",
    "            pixel_num = head['NAXIS1']\n",
    "            specflux = scidata[0,]\n",
    "            ivar = scidata[1,]\n",
    "            wavelength = np.linspace(0, pixel_num - 1, pixel_num)\n",
    "            wavelength = np.power(10, (coeff0 + wavelength * coeff1))\n",
    "            hdulist.close()\n",
    "            \n",
    "        elif len_list == 2:\n",
    "            head = hdulist[0].header\n",
    "            scidata = hdulist[1].data\n",
    "            wavelength = scidata[0][2]\n",
    "            ivar = scidata[0][1]\n",
    "            specflux = scidata[0][0]\n",
    "    \n",
    "        if self.z_corr:\n",
    "            try:\n",
    "                # correct for radial velocity of star\n",
    "                redshift = head['Z']\n",
    "            except Exception:\n",
    "                redshift = 0.0\n",
    "                \n",
    "            wavelength = wavelength - redshift * wavelength\n",
    "    \n",
    "        return np.vstack((wavelength, specflux, ivar)).T"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1064a880-32ef-4e41-b640-31fac752636b",
   "metadata": {},
   "source": [
    "train_dataset = SpectraVDataset(data_root, lamost_spec_dir, spectra_v_file, classes=CLASSES, split='train')\n",
    "val_dataset = SpectraVDataset(data_root, lamost_spec_dir, spectra_v_file, classes=CLASSES, split='val')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99d07264-2332-4a27-924b-72afbc99644f",
   "metadata": {},
   "source": [
    "len(train_dataset), len(val_dataset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4a1beae5-d47c-4705-9c71-5135aaeafddf",
   "metadata": {},
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=False, num_workers=4)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False, num_workers=4)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8118bc36-6134-4ff3-ad57-8c073a8590df",
   "metadata": {},
   "source": [
    "flux, label = next(iter(train_dataloader))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c53915b4-8417-492b-9e3d-39bff5438fcf",
   "metadata": {},
   "source": [
    "plt.plot(train_dataset.readLRSFits(os.path.join(data_root, lamost_spec_dir, train_dataset.df.iloc[1]['spec_filename']))[:, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "827f7961-0ae3-4558-a00b-d41e79a1bca1",
   "metadata": {},
   "source": [
    "plt.plot(flux[0, 0, :])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6eb6762d-8101-4b16-af6a-108efb4e6e38",
   "metadata": {},
   "source": [
    "plt.plot(flux[1, 0, :])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0950d756-8ecf-4c7a-b974-e75a28efc6ae",
   "metadata": {},
   "source": [
    "plt.plot(flux[2, 0, :])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "079b3ea2-4a72-4d0e-949a-32316f86cd23",
   "metadata": {},
   "source": [
    "plt.plot(flux[3, 0, :])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04df2833-129a-4692-94fb-7b5bafbce614",
   "metadata": {},
   "source": [
    "plt.plot(flux[4, 0, :])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "0dbc5a1b-786c-4dab-a384-5d3fde9bdc52",
   "metadata": {},
   "source": [
    "conv1 = nn.Sequential(nn.Conv1d(1, 64, kernel_size=3), nn.ReLU())\n",
    "mp1 = nn.MaxPool1d(kernel_size=4)\n",
    "\n",
    "x1 = conv1(X)\n",
    "print(x1.shape)\n",
    "\n",
    "x2 = mp1(x1)\n",
    "print(x2.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9ae10eef-2ac9-445e-93fb-9053b64dfd8d",
   "metadata": {},
   "source": [
    "conv2 = nn.Sequential(nn.Conv1d(64, 64, kernel_size=3), nn.ReLU())\n",
    "mp2 = nn.MaxPool1d(kernel_size=4)\n",
    "\n",
    "x3 = conv2(x2)\n",
    "print(x3.shape)\n",
    "\n",
    "x4 = mp2(x3)\n",
    "print(x4.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "cf0e7c56-35bd-4f4d-a6b3-2952ee3135be",
   "metadata": {},
   "source": [
    "conv3 = nn.Sequential(nn.Conv1d(64, 32, kernel_size=3), nn.ReLU())\n",
    "mp3 = nn.MaxPool1d(kernel_size=4)\n",
    "\n",
    "x5 = conv3(x4)\n",
    "print(x5.shape)\n",
    "\n",
    "x6 = mp3(x5)\n",
    "print(x6.shape)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f082b054-600c-4d62-a8e6-b54f8ec085b9",
   "metadata": {},
   "source": [
    "conv4 = nn.Sequential(nn.Conv1d(32, 32, kernel_size=3), nn.ReLU())\n",
    "x7 = conv4(x6)\n",
    "x7.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "62c892ff-9b60-484e-aeeb-d23e9731b97a",
   "metadata": {},
   "source": [
    "x8 = x7.view(x7.shape[0], -1)\n",
    "x8.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "f2a4388c-ece8-45b4-a239-fe6b8d3ce6f7",
   "metadata": {},
   "source": [
    "mlp = nn.Sequential(\n",
    "    nn.Linear(32 * 37, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, train_dataset.num_classes)\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "e6abedc3-8614-4fa2-96a1-152eff5107e2",
   "metadata": {},
   "source": [
    "x9 = mlp(x8)\n",
    "x9.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2eda85-94ba-4e84-a06c-8299f7c3e1bc",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed169009-70e8-4b15-a975-c639f6801b51",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab10e4bb-d16e-4873-9e6a-2e6db4c06190",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "16cb4297-9efe-48c5-acc8-819ffcf9edcc",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "19a00579-2c42-40fe-aa2b-c49fbf9f0ce5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8ebe5a00-089b-4bc7-a282-7b34d1e596f3",
   "metadata": {},
   "source": [
    "class GalSpecNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(GalSpecNet, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Sequential(nn.Conv1d(1, 64, kernel_size=3), nn.ReLU())\n",
    "        self.mp1 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.conv2 = nn.Sequential(nn.Conv1d(64, 64, kernel_size=3), nn.ReLU())\n",
    "        self.mp2 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.conv3 = nn.Sequential(nn.Conv1d(64, 32, kernel_size=3), nn.ReLU())\n",
    "        self.mp3 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.conv4 = nn.Sequential(nn.Conv1d(32, 32, kernel_size=3), nn.ReLU())\n",
    "\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(32 * 37, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, num_classes)\n",
    "        )\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.mp1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.mp2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.mp3(x)\n",
    "        x = self.conv4(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "047e2e84-e0c1-4a65-9b24-e40b122a6997",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a07b00fb-2b41-4a05-80bb-fd20d3f264c1",
   "metadata": {},
   "source": [
    "model = ResNet(train_dataset.num_classes)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1a5257-b7f8-403c-8ddc-106bb923f7d9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e44b32db-bcfd-49ca-84c9-2c88b1d52c5c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "8d5cd17a-69aa-458f-97bc-b3cd2ade8ce7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "2d7af7b4-2f4f-4c54-a666-6f96be683c7c",
   "metadata": {
    "scrolled": true
   },
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ac1036b3-ccfc-4b6c-8659-e6a63befa5d0",
   "metadata": {},
   "source": [
    "1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cec91e-93fc-45c2-a331-da36ec3d868c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402451ad-1128-4dcf-bccf-80128e2115b5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f921c568-a282-4f6d-a60e-39d0deea8a4c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3bfabbbb-343b-446b-988c-4efe445e4c6d",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('Only 1 batch norm')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "91d93386-d614-4516-9092-a1544d269f3a",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('Dont remember lol')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2037c38f-9975-44e4-8ac7-61d963c345ff",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('Weight decay 0.1 + Res Connections')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2110ee41-59df-4a75-aac4-814c7eea24a0",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('No max pool')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "fea4af16-1ebe-47e8-b8ac-f8bc08ff64f4",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('MaxPool + Batch Norm but less layers and mlp instead of fc')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "70206d2c-4689-4e38-ab5e-d3bb356a1cc4",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('MaxPool + Batch Norm but less layers')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5db6a9b4-afaa-4de5-a5a0-dadd79810511",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('MaxPool + Batch Norm')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b93bcd18-7405-4e4d-8cf0-0b758c89a21c",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('6 Conv1d (1>64, 64>64, 64>64, 64>128, 128>128, 128>256), 2 MP1d, ReLU, DO(0.8), Flatten, 2 Linear (17920>1024>nc)')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "906393ab-1735-4a70-b415-c2476c61f6ac",
   "metadata": {},
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses on the left side\n",
    "ax1.plot(train_losses, label='Train Loss')\n",
    "ax1.plot(val_losses, label='Validation Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.set_xlabel('Epochs')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "\n",
    "# Plot training and validation accuracies on the right side\n",
    "ax2.plot(train_accs, label='Train Accuracy')\n",
    "ax2.plot(val_accs, label='Validation Accuracy')\n",
    "ax2.set_title('Training and Validation Accuracy')\n",
    "ax2.set_xlabel('Epochs')\n",
    "ax2.set_ylabel('Accuracy')\n",
    "ax2.legend()\n",
    "\n",
    "fig.suptitle('6 Conv1d (1>64, 64>64, 64>64, 64>128, 128>128, 128>256), 2 MP1d, ReLU, DO(0.5), Flatten, 2 Linear (17920>1024>nc)')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5c84c0-19e1-42be-a5db-3cb772e81358",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb46185a-81bd-4e45-8ed2-cd3c1ef75768",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a0983ecd-212e-4262-b947-386e8edb495b",
   "metadata": {},
   "source": [
    "plt.plot(train_losses)\n",
    "plt.plot(val_losses)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d6077542-86f2-4044-8524-aeda9f658223",
   "metadata": {},
   "source": [
    "plt.plot(train_accs)\n",
    "plt.plot(val_accs)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9e43b16-80d1-4659-bf30-17f93b5159fe",
   "metadata": {},
   "source": [
    "for i in range(10, 50):\n",
    "    print(f'Epoch {i}')\n",
    "    \n",
    "    train_loss, train_acc = train_epoch()\n",
    "    print(f'Train Loss: {round(train_loss, 3)} Acc: {round(train_acc, 2)}')\n",
    "    \n",
    "    val_loss, val_acc = val_epoch()\n",
    "    print(f'Val Loss: {round(val_loss, 3)} Acc: {round(val_acc, 2)}')\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d27bbb-12c6-4c41-9988-fa4ff1696a46",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec9bf65-b985-452a-b8dd-137e72386b53",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebcb5ff-3fc3-4aad-896b-af99a6b79093",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3576752a-550e-440a-b6ac-52a646741da9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246f69e7-161b-4120-818e-2af9cea97ae4",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c19e3b5-8725-413e-868f-d7979e0f4bca",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1527999-252f-477c-940d-bcbf18d9aade",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082b2b7-5432-4962-b752-331d81b69759",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f39ffa-6bc0-4817-8f2a-2747b5a4fa32",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbff59f-6e96-45dd-b2a8-654854915170",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c80696b-a8a9-4831-93a2-a7766d173cfd",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a8779-7c9b-4f5a-bd3f-6cf010002dab",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28489a-fe0a-48f4-968c-566077c0f8eb",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea99281-1ff0-46fc-b066-a9a742d1c680",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a5dd2a9a-f099-41a2-a512-6e02efdc1dd9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40cdd513-aae2-432a-aea4-facc7f70da98",
   "metadata": {},
   "source": [
    "datapath = Path('/home/mariia/AstroML/data/asassn')\n",
    "ds_train = ASASSNVarStarDataset(datapath, mode='train', verbose=True, only_periodic=True, recalc_period=False, \n",
    "                                prime=True, use_bands=['v', 'g'], only_sources_with_spectra=True, return_phased=True, \n",
    "                                fill_value=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f51f2586-ad83-4b9c-b986-89f000a984e1",
   "metadata": {},
   "source": [
    "ds_val = ASASSNVarStarDataset(datapath, mode='val', verbose=True, only_periodic=True, recalc_period=False, \n",
    "                              prime=True, use_bands=['v', 'g'], only_sources_with_spectra=True, return_phased=True, \n",
    "                              fill_value=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65a4386-98d0-4c48-b4a3-8c6dbe0af981",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70efbebf-d98a-4d70-9b5a-1e71a702c45e",
   "metadata": {},
   "source": [
    "def preprocess_batch(batch, masks):\n",
    "    lcs, classes = batch\n",
    "    lcs_mask, classes_mask = masks\n",
    "\n",
    "    # shape now [128, 1, 3, 759], make [128, 3, 759] \n",
    "    X = lcs[:, 0, :, :]\n",
    "    \n",
    "    # change axises, shape now [128, 3, 759], make [128, 759, 3]\n",
    "    X = X.transpose(1, 2)\n",
    "    \n",
    "    # since mask is the same for time flux and flux err we can make it 2D\n",
    "    mask = lcs_mask[:, 0, 0, :]\n",
    "\n",
    "    # context length 200, crop X and MASK if longer, pad if shorter\n",
    "    if X.shape[1] < context_length:\n",
    "        X_padding = (0, 0, 0, context_length - X.shape[1], 0, 0)\n",
    "        mask_padding = (0, context_length - X.shape[1])\n",
    "        X = F.pad(X, X_padding)\n",
    "        mask = F.pad(mask, mask_padding, value=True)\n",
    "    else:\n",
    "        X = X[:, :context_length, :]\n",
    "        mask = mask[:, :context_length]\n",
    "\n",
    "    # the last dimention is (time, flux, flux_err), sort it based on time\n",
    "    sort_indices = torch.argsort(X[:, :, 0], dim=1)\n",
    "    sorted_X = torch.zeros_like(X)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        sorted_X[i] = X[i, sort_indices[i]]\n",
    "    \n",
    "    # rearange indexes for masks as well\n",
    "    sorted_mask = torch.zeros_like(mask)\n",
    "    \n",
    "    for i in range(mask.shape[0]):\n",
    "        sorted_mask[i] = mask[i, sort_indices[i]]\n",
    "\n",
    "    # mask should be 1 for values that are observed and 0 for values that are missing\n",
    "    sorted_mask = 1 - sorted_mask.int()\n",
    "\n",
    "    # read scales\n",
    "    with open('scales.json', 'r') as f:\n",
    "        scales = json.load(f)\n",
    "        mean, std = scales['v']['mean'], scales['v']['std']\n",
    "\n",
    "    # scale X\n",
    "    sorted_X[:, :, 1] = (sorted_X[:, :, 1] - mean) / std\n",
    "    sorted_X[:, :, 2] = sorted_X[:, :, 2] / std\n",
    "\n",
    "    # reshape classes to be 1D vector and convert from float to int\n",
    "    classes = classes[:, 0]\n",
    "    classes = classes.long()\n",
    "    \n",
    "    return sorted_X, sorted_mask, classes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac51fd2f-c6bd-47b8-9815-0519726536ec",
   "metadata": {},
   "source": [
    "train_dataset = SpectraDataset(ds_train)\n",
    "val_dataset = SpectraDataset(ds_val)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bcf6d193-03fe-4970-ad87-86eac3523ab2",
   "metadata": {},
   "source": [
    "train_dataset[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "035b5649-5bce-4f7a-9b15-aafa64282e07",
   "metadata": {},
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=512, shuffle=True, num_workers=8)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe5199eb-5ac6-4031-8d7a-62187f3f74da",
   "metadata": {},
   "source": [
    "class GalSpecNet(nn.Module):\n",
    "    \"\"\"https://academic.oup.com/mnras/article/527/1/1163/7283157\"\"\"\n",
    "    \n",
    "    def __init__(self, num_classes):\n",
    "        super(GalSpecNet, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, padding=0)\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=64, kernel_size=3, padding=0)\n",
    "        self.conv3 = nn.Conv1d(in_channels=64, out_channels=32, kernel_size=3, padding=0)\n",
    "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=3, padding=0)\n",
    "\n",
    "        self.mp1 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.mp2 = nn.MaxPool1d(kernel_size=4)\n",
    "        self.mp3 = nn.MaxPool1d(kernel_size=4)\n",
    "\n",
    "        self.fc1 = nn.Linear(2496, 512)\n",
    "        self.fc2 = nn.Linear(512, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, num_classes)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.mp1(self.conv1(x)))\n",
    "        x = F.relu(self.mp2(self.conv2(x)))\n",
    "        x = F.relu(self.mp3(self.conv3(x)))\n",
    "        x = F.relu(self.conv4(x))        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(self.dropout(x)))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5910210-5c58-4419-923d-66680fa0e77e",
   "metadata": {},
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ea722ce5-ac5b-4d55-9cb9-21509cb02199",
   "metadata": {},
   "source": [
    "model = GalSpecNet(len(ds_train.target_lookup))\n",
    "model = model.to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf981bf5-4666-4dd6-82a7-613c44c3f31b",
   "metadata": {},
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b0fc5d9b-7330-4e76-a6b4-d64b15c58aeb",
   "metadata": {},
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for fluxes, label in tqdm(train_dataloader):\n",
    "        fluxes, label = fluxes.to(device), label.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits = model(fluxes)\n",
    "        loss = criterion(logits, label)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "        correct_predictions = (predicted_labels == label).sum().item()\n",
    "\n",
    "        total_correct_predictions += correct_predictions\n",
    "        total_predictions += label.size(0)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return sum(total_loss) / len(total_loss), total_correct_predictions / total_predictions"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b4de5ef-156a-48ed-950d-6fedfb58b204",
   "metadata": {},
   "source": [
    "def val_epoch():\n",
    "    model.eval()\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for fluxes, label in tqdm(val_dataloader):\n",
    "            fluxes, label = fluxes.to(device), label.to(device)\n",
    "\n",
    "            logits = model(fluxes)\n",
    "            loss = criterion(logits, label)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "            _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "            correct_predictions = (predicted_labels == label).sum().item()\n",
    "    \n",
    "            total_correct_predictions += correct_predictions\n",
    "            total_predictions += label.size(0)\n",
    "\n",
    "    return sum(total_loss) / len(total_loss), total_correct_predictions / total_predictions"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c42747ed-cc7b-4fb9-b376-c28576fa9d40",
   "metadata": {},
   "source": [
    "for i in range(10):\n",
    "    print(f'Epoch {i}')\n",
    "    \n",
    "    train_loss, train_acc = train_epoch()\n",
    "    print(f'Train Loss: {round(train_loss, 3)} Acc: {round(train_acc, 2)}')\n",
    "    \n",
    "    val_loss, val_acc = val_epoch()\n",
    "    print(f'Val Loss: {round(val_loss, 3)} Acc: {round(val_acc, 2)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "918cf0c9-4756-4351-8089-51e1ee71112d",
   "metadata": {},
   "source": [
    "for i in range(10, 100):\n",
    "    print(f'Epoch {i}')\n",
    "    \n",
    "    train_loss, train_acc = train_epoch()\n",
    "    print(f'Train Loss: {round(train_loss, 3)} Acc: {round(train_acc, 2)}')\n",
    "    \n",
    "    val_loss, val_acc = val_epoch()\n",
    "    print(f'Val Loss: {round(val_loss, 3)} Acc: {round(val_acc, 2)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fd2204-ac4c-4f44-a175-f278b80e1e13",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031db3ec-c964-4000-b730-7b1eb137ac50",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01f53d4-3e99-4516-b14f-e43e28d1a917",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c734dc98-4360-4e1b-885e-2a3c2ac17504",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), f'weights-10.pth')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "19179328-b00b-4fb7-940c-32eb05fc04d6",
   "metadata": {},
   "source": [
    "for i in range(10, 100):\n",
    "    print(f'Epoch {i}')\n",
    "    print('Train', train_epoch())\n",
    "    print('Val', val_epoch())\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        torch.save(model.state_dict(), f'weights-{i}.pth')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d03380f8-b46f-40ef-a146-5fd15828d8c2",
   "metadata": {},
   "source": [
    "for i in tqdm(range(len(ds_train))):\n",
    "    if ds_train[i]['spectra'][0][0][:, 1].dtype != np.float32:\n",
    "        print(i)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65b5650-7848-4447-a236-7715ec20ad30",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2d4603-36f1-4acd-a68d-58488212bb2c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc3f302-9bb9-4703-8398-4d4f7f974128",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65927a0-3d5c-4574-9006-953652cbd673",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b68ddc-a9f2-4add-b9b1-28d4fab3c484",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876fb40f-0a5c-4681-ba33-f44d72eb6805",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38dfc54a-a4f4-44da-a176-27c82d706721",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153644f6-3666-44ef-afbe-f9237de14ca8",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c3c317-e2bb-499a-956a-dbf2c82d3822",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09b088-0531-464a-b27e-2680b38943b3",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbbf56e-0608-470c-ad07-f3cf9d306d61",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71f28e3-8fca-494d-bb72-e6287c984593",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351af772-83a5-4d85-a2df-5ded66c593a8",
   "metadata": {},
   "source": [
    "for i in tqdm(range(len(ds_train))):\n",
    "    try:\n",
    "        spectra = ds_train[i]['spectra'][0][0]\n",
    "    except:\n",
    "        print(i)\n",
    "        break"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "868382fe-c729-49ea-90d9-8f8c74a72305",
   "metadata": {},
   "source": [
    "spec_filename = ds_train.spec_df[ds_train.spec_df['edr3_source_id'] == 'EDR3 1314026659889734400']['spec_filename'].iloc[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "415b2050-dd4e-4ba8-b7f1-291845e4dfae",
   "metadata": {},
   "source": [
    "remove_filenames = []\n",
    "\n",
    "for el in ds_train.spec_df['spec_filename']:\n",
    "    filename = (ds_train.data_root / ds_train.lamost_spec_dir / el)\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        remove_filenames.append(str(filename).split('/')[-1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d43993ac-6180-405f-97bc-3df0556c6d19",
   "metadata": {},
   "source": [
    "ds_train.spec_df[ds_train.spec_df['spec_filename'].isin(remove_filenames)].index"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49ef483-2864-4bc0-967f-c5a4264d2c85",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e9c4f3ac-f1c3-406e-87f0-386e8d533ea4",
   "metadata": {},
   "source": [
    "filename = (ds_train.data_root / ds_train.lamost_spec_dir / spec_filename)\n",
    "\n",
    "if os.path.exists(filename):\n",
    "    row_spectra.append(self._readLRSFits(filename))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "ce8fa24a-0d4e-4270-8682-d51a11168638",
   "metadata": {},
   "source": [
    "os.path.exists(filename)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4feb8594-859f-448b-9a53-bfe44b12f7b9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf7dc4e-afbd-41c6-9f2e-8b459bc619b6",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863034e7-4574-45c1-b740-654d458eb721",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fe6a0-07b0-450f-8fe9-fda10b4ce559",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "07cc5505-72a0-4419-9a25-e413ecf021f4",
   "metadata": {},
   "source": [
    "fig, axs = plt.subplots(nrows=5, ncols=2, figsize=(15, 20))\n",
    "\n",
    "for i in range(5):\n",
    "    spectra = ds_train[i]['spectra'][0][0]\n",
    "    y = ds_train[i]['classes'][0][0]\n",
    "\n",
    "    wavelengths, fluxes = spectra[:, 0], spectra[:, 1]\n",
    "    regular_wavelengths = np.arange(3850, 9002, 2)\n",
    "    interpolated_fluxes = np.interp(regular_wavelengths, wavelengths, fluxes)\n",
    "\n",
    "    axs[i, 0].plot(wavelengths, fluxes)\n",
    "    axs[i, 0].set_title(f'Class {ds_train.target_lookup[y]} Before Interpolation')\n",
    "    axs[i, 1].plot(regular_wavelengths, interpolated_fluxes)\n",
    "    axs[i, 1].set_title(f'Class {ds_train.target_lookup[y]} After Interpolation')\n",
    "\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c5e7ab-da1c-48a1-a44e-17d2c5c88937",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa3cc70-1b0f-4532-a3fe-aa569d5c97d9",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587cefd8-faa2-4bc9-8f7d-08d1bf2b5ed7",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfad693-5748-4394-a869-49b0b0978d51",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46548185-f59e-470b-a99a-b8649365b45a",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2832a53d-8d88-41a4-b614-fd15d5a640b5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4deb050c-9015-46b3-8fca-7b7ebfd103d8",
   "metadata": {},
   "source": [
    "ds_train[i]['spectra'][0][0][:, 0].min(), ds_train[i]['spectra'][0][0][:, 0].max()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df47434c-3dd7-43ae-a080-57af72e7cde2",
   "metadata": {},
   "source": [
    "ds_train.df['variable_type'].value_counts()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863042bf-2238-4c18-9d62-fe56cb108a2c",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d032920-8207-4355-a199-e591bf406156",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72257ac-3f81-48ea-905b-3f17c6c991a8",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
