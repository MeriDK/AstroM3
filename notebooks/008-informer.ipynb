{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "226e1dbb-2b33-4004-a2de-df04ab0670b0",
   "metadata": {},
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bec519f-894f-428c-b26b-6b85c8d7bbf0",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import InformerConfig, InformerModel \n",
    "from transformers.models.informer.modeling_informer import InformerEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from scipy import stats\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "from pathlib import Path\n",
    "from core.multimodal.dataset import collate_fn, ASASSNVarStarDataset\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from models.Informer import Informer"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d505eecb-963c-47ad-9df7-d33f934f9a1e",
   "metadata": {},
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1052ee40-081f-403c-ba70-408eded2e01e",
   "metadata": {},
   "source": [
    "datapath = Path('../data/asassn')\n",
    "ds_train = ASASSNVarStarDataset(datapath, mode='train', verbose=True, only_periodic=True, recalc_period=False, \n",
    "                                prime=True, use_bands=['v'], only_sources_with_spectra=False, return_phased=True, \n",
    "                                fill_value=0)\n",
    "ds_val = ASASSNVarStarDataset(datapath, mode='val', verbose=True, only_periodic=True, recalc_period=False, \n",
    "                              prime=True, use_bands=['v'], only_sources_with_spectra=False, return_phased=True, \n",
    "                              fill_value=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab0acfca-e2d4-4468-b86d-cf8c3f139ecf",
   "metadata": {},
   "source": [
    "context_length = 200\n",
    "\n",
    "no_spectra_data_keys = ['lcs', 'classes']\n",
    "no_spectra_collate_fn = partial(collate_fn, data_keys=no_spectra_data_keys, fill_value=0)\n",
    "\n",
    "train_dataloader = DataLoader(ds_train, batch_size=512, shuffle=True, num_workers=0, \n",
    "                              collate_fn=no_spectra_collate_fn)\n",
    "val_dataloader = DataLoader(ds_val, batch_size=512, shuffle=False, collate_fn=no_spectra_collate_fn)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5919d2a3-71ea-448b-82b4-1083fc301c58",
   "metadata": {},
   "source": [
    "def preprocess_batch(batch, masks):\n",
    "    lcs, classes = batch\n",
    "    lcs_mask, classes_mask = masks\n",
    "\n",
    "    # shape now [128, 1, 3, 759], make [128, 3, 759] \n",
    "    X = lcs[:, 0, :, :]\n",
    "    \n",
    "    # change axises, shape now [128, 3, 759], make [128, 759, 3]\n",
    "    X = X.transpose(1, 2)\n",
    "    \n",
    "    # since mask is the same for time flux and flux err we can make it 2D\n",
    "    mask = lcs_mask[:, 0, 0, :]\n",
    "\n",
    "    # context length 200, crop X and MASK if longer, pad if shorter\n",
    "    if X.shape[1] < context_length:\n",
    "        X_padding = (0, 0, 0, context_length - X.shape[1], 0, 0)\n",
    "        mask_padding = (0, context_length - X.shape[1])\n",
    "        X = F.pad(X, X_padding)\n",
    "        mask = F.pad(mask, mask_padding, value=True)\n",
    "    else:\n",
    "        X = X[:, :context_length, :]\n",
    "        mask = mask[:, :context_length]\n",
    "\n",
    "    # the last dimention is (time, flux, flux_err), sort it based on time\n",
    "    sort_indices = torch.argsort(X[:, :, 0], dim=1)\n",
    "    sorted_X = torch.zeros_like(X)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        sorted_X[i] = X[i, sort_indices[i]]\n",
    "    \n",
    "    # rearange indexes for masks as well\n",
    "    sorted_mask = torch.zeros_like(mask)\n",
    "    \n",
    "    for i in range(mask.shape[0]):\n",
    "        sorted_mask[i] = mask[i, sort_indices[i]]\n",
    "\n",
    "    # mask should be 1 for values that are observed and 0 for values that are missing\n",
    "    sorted_mask = 1 - sorted_mask.int()\n",
    "\n",
    "    # read scales\n",
    "    with open('scales.json', 'r') as f:\n",
    "        scales = json.load(f)\n",
    "        mean, std = scales['v']['mean'], scales['v']['std']\n",
    "\n",
    "    # scale X\n",
    "    sorted_X[:, :, 1] = (sorted_X[:, :, 1] - mean) / std\n",
    "    sorted_X[:, :, 2] = sorted_X[:, :, 2] / std\n",
    "\n",
    "    # reshape classes to be 1D vector and convert from float to int\n",
    "    classes = classes[:, 0]\n",
    "    classes = classes.long()\n",
    "    \n",
    "    return sorted_X, sorted_mask, classes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb212e21-1b83-4fe5-86f5-2c14296be384",
   "metadata": {},
   "source": [
    "model = Informer(enc_in=2, d_model=64, dropout=0.1, factor=1, output_attention=False, n_heads=4, d_ff=512,\n",
    "                 activation='gelu', e_layers=2, seq_len=200, num_class=len(ds_train.target_lookup))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4fbc2066-6a94-452d-b101-5a5c7dce150f",
   "metadata": {},
   "source": [
    "batch, masks = next(iter(train_dataloader))\n",
    "X, mask, y = preprocess_batch(batch, masks)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeff3b30-be6e-4761-b850-85a2a42f7073",
   "metadata": {},
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c8e8feef-1f05-46ec-89d8-8d82bec2f68e",
   "metadata": {},
   "source": [
    "model = model.to(device)\n",
    "X, mask = X.to(device), mask.to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bf901d9-a5e4-4203-9141-5842ded6c56e",
   "metadata": {},
   "source": [
    "X.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "683f8da6-8261-4de9-8eba-23103ef935e7",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    output = model(X[:, :, 1:], mask)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8786222b-ab27-4920-b762-f519d3283965",
   "metadata": {},
   "source": [
    "output.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf9f0d-e5ce-4ea6-b49e-eab4c5be6463",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4ad9d18-9fcc-45ab-abb9-3f64ed748ca4",
   "metadata": {},
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for batch, masks in tqdm(train_dataloader):\n",
    "        X, m, y = preprocess_batch(batch, masks)\n",
    "        X, m, y = X.to(device), m.to(device), y.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        logits = model(X[:, :, 1:], m)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss.append(loss.item())\n",
    "    \n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "        correct_predictions = (predicted_labels == y).sum().item()\n",
    "    \n",
    "        total_correct_predictions += correct_predictions\n",
    "        total_predictions += y.size(0)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Train Total Loss: {round(sum(total_loss) / len(total_loss), 5)} Accuracy: {round(total_correct_predictions / total_predictions, 3)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cad9c1fc-8b98-4f58-9204-ba3cf4c32398",
   "metadata": {},
   "source": [
    "def val_epoch():\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, masks in tqdm(val_dataloader):\n",
    "            X, m, y = preprocess_batch(batch, masks)\n",
    "            X, m, y = X.to(device), m.to(device), y.to(device)\n",
    "\n",
    "            logits = model(X[:, :, 1:], m)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "            _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "            correct_predictions = (predicted_labels == y).sum().item()\n",
    "\n",
    "            total_correct_predictions += correct_predictions\n",
    "            total_predictions += y.size(0)\n",
    "\n",
    "    print(f'Val Total Loss: {round(sum(total_loss) / len(total_loss), 5)} Accuracy: {round(total_correct_predictions / total_predictions, 3)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a644c915-cab0-452e-afd4-3ec1974040ad",
   "metadata": {},
   "source": [
    "def plot_confusion(all_true_labels, all_predicted_labels):\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "\n",
    "    # Calculate percentage values for confusion matrix\n",
    "    conf_matrix_percent = 100 * conf_matrix / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Plot both confusion matrices side by side\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 20))\n",
    "\n",
    "    # Plot absolute values confusion matrix\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('True')\n",
    "    axes[0].set_title('Confusion Matrix - Absolute Values')\n",
    "\n",
    "    # Plot percentage values confusion matrix\n",
    "    sns.heatmap(conf_matrix_percent, annot=True, fmt='.0f', cmap='Blues', ax=axes[1])\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('True')\n",
    "    axes[1].set_title('Confusion Matrix - Percentages')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "704c54de-f41d-4e9b-8d16-fa1bdf08e2cc",
   "metadata": {},
   "source": [
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bd44b609-f0fb-410c-b8e3-06df79d523c7",
   "metadata": {},
   "source": [
    "for i in range(10):\n",
    "    print(f'Epoch {i}')\n",
    "    train_epoch()\n",
    "    val_epoch()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bd35a9-8db3-4bc5-8783-687c014f26aa",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8da123-2a38-4e3f-8ef4-dbd979e3b2c8",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3b89ac-cdb4-4fc3-9d91-92f575af9d2b",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bce5446-9e22-4ff0-b462-74fcde478125",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe1fefb-ee83-4a30-ba41-b8f91e76b39d",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67bc747-c2cd-4790-979d-266e3e496cd2",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0063a8c8-a206-4eb0-9bec-12c2811b85a5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2dfa89-ca0d-47aa-bab6-227df83e6624",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af0e54-8ee8-46af-b96a-31f7fd52ce8f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06a21d7-87a3-4789-95ea-31281163156b",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
