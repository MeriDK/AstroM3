{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43b6596-b2ff-442e-a47c-b8c26b20c4ac",
   "metadata": {},
   "source": [
    "import sys\n",
    "\n",
    "sys.path.insert(0, '..')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "419e394a-cbd7-4bf5-868f-f0b7411f9749",
   "metadata": {},
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction, TimeSeriesTransformerModel \n",
    "from transformers.models.time_series_transformer.modeling_time_series_transformer import TimeSeriesTransformerEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from scipy import stats\n",
    "import json \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "from core.dataset import MachoDataset\n",
    "from core.trainer import PredictionTrainer, ClassificationTrainer\n",
    "from core.model import ClassificationModel\n",
    "\n",
    "from pathlib import Path\n",
    "from core.dataset_multimodal import collate_fn, ASASSNVarStarDataset\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e450f854-706a-4371-b5aa-a727f227ffbb",
   "metadata": {},
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)\n",
    "torch.backends.cudnn.deterministic = True"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71d09e5b-1aab-4b76-95cb-0e70ade41741",
   "metadata": {},
   "source": [
    "datapath = Path('../data/asaasn')\n",
    "ds_train = ASASSNVarStarDataset(datapath, mode='train', verbose=True, only_periodic=True, recalc_period=False, \n",
    "                                prime=True, use_bands=['v'], only_sources_with_spectra=True, return_phased=True, \n",
    "                                fill_value=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a039910-3f82-497f-9103-ba7364435c8a",
   "metadata": {},
   "source": [
    "ds_val = ASASSNVarStarDataset(datapath, mode='val', verbose=True, only_periodic=True, recalc_period=False, \n",
    "                              prime=True, use_bands=['v'], only_sources_with_spectra=True, return_phased=True, fill_value=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8b650a3c-5060-45b2-ab5a-662a49a55294",
   "metadata": {},
   "source": [
    "ds_all = ASASSNVarStarDataset(datapath, mode=None, verbose=True, only_periodic=True, recalc_period=False, \n",
    "                              prime=True, use_bands=['v'], only_sources_with_spectra=True, return_phased=True, fill_value=0)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6ff117e-5345-4ddf-a570-1403bc1bf3c6",
   "metadata": {},
   "source": [
    "ds_train.df['id']"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85375112-38f4-4e88-a01c-3a6a37dbb223",
   "metadata": {},
   "source": [
    "(ds_val.df['id'].isin(ds_train.df['id'])).sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8589201-69fb-4415-acb5-6a44be46c520",
   "metadata": {},
   "source": [
    "(ds_train.df['id'].isin(ds_val.df['id'])).sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1dab825c-23ea-47f8-9bc6-58446b879133",
   "metadata": {},
   "source": [
    "(ds_val.df['id'].isin(ds_all.df['id'])).sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13ef1ee0-4410-471a-b9fa-2bac72145e19",
   "metadata": {},
   "source": [
    "no_spectra_data_keys = ['lcs', 'classes']\n",
    "no_spectra_collate_fn = partial(collate_fn, data_keys=no_spectra_data_keys, fill_value=0)\n",
    "\n",
    "train_dataloader = DataLoader(ds_train, batch_size=512, shuffle=True, pin_memory=True, num_workers=8, \n",
    "                              collate_fn=no_spectra_collate_fn)\n",
    "val_dataloader = DataLoader(ds_val, batch_size=512, shuffle=False, pin_memory=True, num_workers=8,\n",
    "                            collate_fn=no_spectra_collate_fn)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88ce63e8-1d1e-4598-b5b6-bc158b02d26b",
   "metadata": {},
   "source": [
    "context_length = 200"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6f0d261-3319-4436-ac9b-0a5e0b1c344f",
   "metadata": {},
   "source": [
    "def preprocess_batch(batch, masks):\n",
    "    lcs, classes = batch\n",
    "    lcs_mask, classes_mask = masks\n",
    "\n",
    "    # shape now [128, 1, 3, 759], make [128, 3, 759] \n",
    "    X = lcs[:, 0, :, :]\n",
    "    \n",
    "    # change axises, shape now [128, 3, 759], make [128, 759, 3]\n",
    "    X = X.transpose(1, 2)\n",
    "    \n",
    "    # since mask is the same for time flux and flux err we can make it 2D\n",
    "    mask = lcs_mask[:, 0, 0, :]\n",
    "\n",
    "    # context length 200, crop X and MASK if longer, pad if shorter\n",
    "    if X.shape[1] < context_length:\n",
    "        X_padding = (0, 0, 0, context_length - X.shape[1], 0, 0)\n",
    "        mask_padding = (0, context_length - X.shape[1])\n",
    "        X = F.pad(X, X_padding)\n",
    "        mask = F.pad(mask, mask_padding, value=True)\n",
    "    else:\n",
    "        X = X[:, :context_length, :]\n",
    "        mask = mask[:, :context_length]\n",
    "\n",
    "    # the last dimention is (time, flux, flux_err), sort it based on time\n",
    "    sort_indices = torch.argsort(X[:, :, 0], dim=1)\n",
    "    sorted_X = torch.zeros_like(X)\n",
    "    \n",
    "    for i in range(X.shape[0]):\n",
    "        sorted_X[i] = X[i, sort_indices[i]]\n",
    "    \n",
    "    # rearange indexes for masks as well\n",
    "    sorted_mask = torch.zeros_like(mask)\n",
    "    \n",
    "    for i in range(mask.shape[0]):\n",
    "        sorted_mask[i] = mask[i, sort_indices[i]]\n",
    "\n",
    "    # mask should be 1 for values that are observed and 0 for values that are missing\n",
    "    sorted_mask = 1 - sorted_mask.int()\n",
    "\n",
    "    # read scales\n",
    "    with open('scales.json', 'r') as f:\n",
    "        scales = json.load(f)\n",
    "        mean, std = scales['v']['mean'], scales['v']['std']\n",
    "\n",
    "    # scale X\n",
    "    sorted_X[:, :, 1] = (sorted_X[:, :, 1] - mean) / std\n",
    "    sorted_X[:, :, 2] = sorted_X[:, :, 2] / std\n",
    "\n",
    "    # reshape classes to be 1D vector and convert from float to int\n",
    "    classes = classes[:, 0]\n",
    "    classes = classes.long()\n",
    "\n",
    "    return sorted_X, sorted_mask, classes"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4efc3e1e-6739-49ee-a839-129ac05d7787",
   "metadata": {},
   "source": [
    "batch, masks = next(iter(train_dataloader))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3946ba81-4544-457e-bdb5-be5ee2da9e3e",
   "metadata": {},
   "source": [
    "X, m, y = preprocess_batch(batch, masks)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94af81d6-037e-40e6-943e-904feb4e6930",
   "metadata": {},
   "source": [
    "X.shape, m.shape, y.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9b3ba417-b0c8-4ccf-a4d1-45c1da60e1ec",
   "metadata": {},
   "source": [
    "y.dtype"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8f3c47e-b0b4-4681-8af1-d81b683c2584",
   "metadata": {},
   "source": [
    "config = TimeSeriesTransformerConfig(\n",
    "    prediction_length=20,    # doesn't matter but it's required by hf\n",
    "    context_length=context_length,\n",
    "    num_time_features=1,\n",
    "    num_static_real_features=0,\n",
    "    encoder_layers=2,\n",
    "    d_model=64,\n",
    "    distribution_output='normal',\n",
    "    scaling=None,\n",
    "    dropout=0,\n",
    "    encoder_layerdrop=0,\n",
    "    attention_dropout=0,\n",
    "    activation_dropout=0\n",
    ")\n",
    "\n",
    "config.feature_size = 2    # flux and flux err"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee2f0db3-be13-45af-b7c7-85587f2ca7c0",
   "metadata": {},
   "source": [
    "device = torch.device('cuda:7' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d4dbf26-5670-472e-b6f3-3d6173d96551",
   "metadata": {},
   "source": [
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, encoder, num_classes):\n",
    "        super(CustomModel, self).__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.num_classes = num_classes\n",
    "        self.classifier = nn.Linear(self.encoder.config.d_model, num_classes)\n",
    "\n",
    "    def forward(self, values, mask):\n",
    "        encoder_outputs = self.encoder(inputs_embeds=values, attention_mask=mask)\n",
    "        emb = encoder_outputs.last_hidden_state[:, 0, :]     # we will use the 1 element only, analog to CLS?\n",
    "        res = self.classifier(emb)\n",
    "\n",
    "        return res"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "586b40e7-8b15-410d-9c79-598071ddb33d",
   "metadata": {},
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for batch, masks in tqdm(train_dataloader):\n",
    "        X, m, y = preprocess_batch(batch, masks)\n",
    "        X, m, y = X.to(device), m.to(device), y.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        logits = model(X[:, :, 1:], m)\n",
    "        loss = criterion(logits, y)\n",
    "        total_loss.append(loss.item())\n",
    "    \n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "        correct_predictions = (predicted_labels == y).sum().item()\n",
    "    \n",
    "        total_correct_predictions += correct_predictions\n",
    "        total_predictions += y.size(0)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Train Total Loss: {round(sum(total_loss) / len(total_loss), 5)} Accuracy: {round(total_correct_predictions / total_predictions, 3)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3f43cfb-953b-4a7d-bb2d-14a60b7c2134",
   "metadata": {},
   "source": [
    "def val_epoch():\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch, masks in tqdm(val_dataloader):\n",
    "            X, m, y = preprocess_batch(batch, masks)\n",
    "            X, m, y = X.to(device), m.to(device), y.to(device)\n",
    "\n",
    "            logits = model(X[:, :, 1:], m)\n",
    "            loss = criterion(logits, y)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "            _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "            correct_predictions = (predicted_labels == y).sum().item()\n",
    "\n",
    "            total_correct_predictions += correct_predictions\n",
    "            total_predictions += y.size(0)\n",
    "\n",
    "    print(f'Val Total Loss: {round(sum(total_loss) / len(total_loss), 5)} Accuracy: {round(total_correct_predictions / total_predictions, 3)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "07e401c8-49ba-4bad-8060-78c8f01c9b44",
   "metadata": {},
   "source": [
    "def plot_confusion(all_true_labels, all_predicted_labels):\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "\n",
    "    # Calculate percentage values for confusion matrix\n",
    "    conf_matrix_percent = 100 * conf_matrix / conf_matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    # Plot both confusion matrices side by side\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(10, 20))\n",
    "\n",
    "    # Plot absolute values confusion matrix\n",
    "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
    "    axes[0].set_xlabel('Predicted')\n",
    "    axes[0].set_ylabel('True')\n",
    "    axes[0].set_title('Confusion Matrix - Absolute Values')\n",
    "\n",
    "    # Plot percentage values confusion matrix\n",
    "    sns.heatmap(conf_matrix_percent, annot=True, fmt='.0f', cmap='Blues', ax=axes[1])\n",
    "    axes[1].set_xlabel('Predicted')\n",
    "    axes[1].set_ylabel('True')\n",
    "    axes[1].set_title('Confusion Matrix - Percentages')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "81a23246-c585-439a-9944-46017af30e4b",
   "metadata": {},
   "source": [
    "encoder = TimeSeriesTransformerEncoder(config)\n",
    "model = CustomModel(encoder, num_classes=len(ds_train.target_lookup.keys()))\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a00620c-5b14-4875-9bc9-08775514cbf3",
   "metadata": {},
   "source": [
    "model.load_state_dict(torch.load('/home/mrizhko/AML/AstroML/weights.pth'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29ee8cb9-25fa-434b-9d3a-88525aa39362",
   "metadata": {},
   "source": [
    "val_epoch()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f8f91a3-41cf-4432-bc6a-f00dfef60497",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "\n",
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for batch, masks in tqdm(val_dataloader):\n",
    "        X, m, y = preprocess_batch(batch, masks)\n",
    "        X, m = X.to(device), m.to(device)\n",
    "\n",
    "        logits = model(X[:, :, 1:], m)\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "\n",
    "        y_pred.append(predicted_labels)\n",
    "        y_true.append(y)\n",
    "\n",
    "y_pred = torch.hstack(y_pred).cpu()\n",
    "y_true = torch.hstack(y_true)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c9269cc-7076-47f0-8f1e-6d57e1a22a9c",
   "metadata": {},
   "source": [
    "plot_confusion(y_true, y_pred)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad89076-0d76-42f4-b698-6383ec31adf1",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "515edf9c-c0a3-4ea9-be94-18ee88843dfc",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a0835b-7a12-47d9-b2ae-cf5b58ee45b4",
   "metadata": {},
   "source": [
    "for i in range(100):\n",
    "    print(f'Epoch {i}', end=' ')\n",
    "    train_epoch()\n",
    "    val_epoch()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7a89d79-e614-4c93-b902-14a6b3423bea",
   "metadata": {},
   "source": [
    "val_epoch()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f099ebd7-3ad4-4319-9164-15bd470f7814",
   "metadata": {},
   "source": [
    "torch.save(model.state_dict(), 'weight.pth')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa927642-c79e-4023-9456-4a4c3f3244af",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7a96ef-3436-425f-861e-66e0e17e9e45",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5486b2-04fa-4106-8798-7f2c4dd58f96",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa41dc-70e4-47af-a232-373e5e6ce85f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d3d8a-7a90-4e1a-af00-0283bfeedeac",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4a8991-fcfa-4b3a-a0bb-eeff6cd98f85",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14afc048-af95-48ec-b938-fcbd155da16e",
   "metadata": {},
   "source": [
    "encoder(inputs_embeds=X[:, :, 1:], attention_mask=m).last_hidden_state"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "e1ab18ba-f468-48e6-bcf9-4dab11bdfe8a",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "aa3839af-a5d3-4f2a-9a3e-c9749c3f6aa5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "52fc179f-69ac-45a8-b39b-f08e27bc5a04",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "68d85582-a3dc-41c0-add3-d44c52c13d75",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "21e7f586-9b7a-41f7-9172-93701b1f2331",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "8aab056f-8099-449a-b1b2-a1ad03c8dad9",
   "metadata": {},
   "source": [
    "def train_epoch():\n",
    "    model.train()\n",
    "\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    \n",
    "    for batch in train_dataloader:\n",
    "        _, times, _, values, _, mask, aux, labels = batch\n",
    "        labels = labels.to(device)\n",
    "        values, mask = values.to(device), mask.to(device)\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        logits = model(values, mask)\n",
    "        loss = criterion(logits, labels)\n",
    "        total_loss.append(loss.item())\n",
    "    \n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "        correct_predictions = (predicted_labels == labels).sum().item()\n",
    "    \n",
    "        total_correct_predictions += correct_predictions\n",
    "        total_predictions += labels.size(0)\n",
    "    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Total Loss: {round(sum(total_loss) / len(total_loss), 5)} Accuracy: {round(total_correct_predictions / total_predictions, 3)}', end=' ')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8b64140a-cd14-4d0c-9791-bee06c78a833",
   "metadata": {},
   "source": [
    "def val_epoch():\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            _, times, _, values, _, mask, aux, labels = batch\n",
    "            labels = labels.to(device)\n",
    "            values, mask = values.to(device), mask.to(device)\n",
    "\n",
    "            logits = model(values, mask)\n",
    "            loss = criterion(logits, labels)\n",
    "            total_loss.append(loss.item())\n",
    "\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "            _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "            correct_predictions = (predicted_labels == labels).sum().item()\n",
    "\n",
    "            total_correct_predictions += correct_predictions\n",
    "            total_predictions += labels.size(0)\n",
    "\n",
    "    print(f'Total Loss: {round(sum(total_loss) / len(total_loss), 5)} Accuracy: {round(total_correct_predictions / total_predictions, 3)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0b3dad-925b-45bf-ba1a-9b11da7a3a5e",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed6129b-eb6e-408e-95f3-28b6b73800d6",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "f1e8a96c-d1b9-4603-bdc4-6ad7051e01d2",
   "metadata": {},
   "source": [
    "plt.plot(X[0, :, 0], X[0, :, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1ba55752-1054-4930-8f14-4518c9fcc358",
   "metadata": {},
   "source": [
    "plt.plot(X[0, :, 0], X[0, :, 1], '.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "b640b761-9ae1-48e5-8bd4-7d23300f9ced",
   "metadata": {},
   "source": [
    "plt.plot(sorted_X[0, :, 0], sorted_X[0, :, 1])"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "70dddd26-330c-4a27-ac2d-c45c942676a1",
   "metadata": {},
   "source": [
    "plt.plot(sorted_X[0, :, 0], sorted_X[0, :, 1], '.')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "ded3eab9-be71-4e3e-b806-e498409051c8",
   "metadata": {},
   "source": [
    "(sorted_X[0, :, 0] * ~sorted_mask[0]).sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "700cab6e-1118-42c8-a7e6-759e62309cd1",
   "metadata": {},
   "source": [
    "sorted_X[0, :, 0].sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3d6a3643-7cff-4e2f-9506-6f3f3f5e2a19",
   "metadata": {},
   "source": [
    "m"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "64f7db4f-d585-4057-bbfd-f61899522b80",
   "metadata": {},
   "source": [
    "classes.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1601b9-21f5-4ff7-81e8-f124565d7285",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52a927ab-674c-4812-8106-9d53cef9929f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ab676f-436e-4aba-a312-2c30694e4fd6",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac976b7-2d81-43dd-8331-54e6e8de15bb",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c464e59-6201-4f04-b1a1-93bd2b3aea1f",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fad42003-b301-4a23-8cb8-c799547a71f8",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "524084f3-2b78-4f5f-843f-062f82f27a98",
   "metadata": {},
   "source": [
    "model = TimeSeriesTransformerModel(config)\n",
    "model = embedder.to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0203832-9f2c-4ef1-9416-046f80f45750",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0b068437-a258-46c1-b956-462efc802269",
   "metadata": {},
   "source": [
    "encoder = TimeSeriesTransformerEncoder(config)\n",
    "# encoder = encoder.to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3aff20b7-b756-4f17-be3a-3b707e288439",
   "metadata": {},
   "source": [
    "lcs.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7bbcd8ed-d1ea-412f-ae2d-3f912bfecbe9",
   "metadata": {},
   "source": [
    "lcs = lcs.transpose(1, -1)\n",
    "lcs.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8e8caf6e-de38-4813-9040-abd98a9b127c",
   "metadata": {},
   "source": [
    "enc_input = lcs[:, :, 1:, 0]\n",
    "# enc_input = enc_input.to(device)\n",
    "enc_input.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ab03b009-d2cd-473c-a3fb-9f00b479a77e",
   "metadata": {},
   "source": [
    "lcs_mask = lcs_mask.transpose(1, -1)\n",
    "lcs_mask.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "34264fc1-492e-498e-a4bb-ddf7caaf9bc2",
   "metadata": {},
   "source": [
    "(lcs_mask[:, :, 1, 0] != lcs_mask[:, :, 2, 0]).sum()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ce03d1b2-4445-4b8b-bdca-ac34349b2b81",
   "metadata": {},
   "source": [
    "attention_mask = lcs_mask[:, :, 1, 0]\n",
    "attention_mask.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "887a3d6c-5f88-496a-bb52-5058c853ccd6",
   "metadata": {},
   "source": [
    "# inputs_embeds `torch.FloatTensor` of shape `(batch_size, sequence_length, hidden_size) 128 570 2\n",
    "encoder_outputs = encoder(\n",
    "    inputs_embeds=enc_input,\n",
    "    attention_mask=attention_mask,\n",
    "    head_mask=None,\n",
    "    output_attentions=None,\n",
    "    output_hidden_states=None,\n",
    "    return_dict=None,\n",
    ")"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ddd0150e-5c86-4c51-bb8f-54ee4ad10aad",
   "metadata": {},
   "source": [
    "past_time_features = lcs[:, :, 0, 0:]\n",
    "past_time_features.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "0a47c087-0fe7-463f-97b6-f59caa18f3d4",
   "metadata": {},
   "source": [
    "encoder_outputs.last_hidden_state.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c88bdac2-4b4a-49df-bced-c04c6e646759",
   "metadata": {},
   "source": [
    "model = ClassificationModel(pretrained_model=embedder, device=device)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.3, patience=10, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2dc9902c-47bd-4742-a97b-46801c118f58",
   "metadata": {},
   "source": [
    "values = lcs[:, 0, 1, :]\n",
    "time_features = lcs[:, 0, 0, :]\n",
    "observed_mask = masks[0][:, 0, 0, :]"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bf03c34a-db43-4300-b7ed-755e473d37de",
   "metadata": {},
   "source": [
    "values.shape, time_features.shape, observed_mask.shape"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097dca4e-1a06-4981-85d7-bb473295ac2a",
   "metadata": {},
   "source": [
    "outputs = self.pretrained_model(\n",
    "    past_time_features=past_times.to(self.device),\n",
    "    past_values=past_values.to(self.device),\n",
    "    future_time_features=future_times.to(self.device),\n",
    "    past_observed_mask=past_mask.to(self.device),\n",
    "    static_real_features=static_real_features\n",
    ")\n",
    "\n",
    "# embedding = torch.mean(outputs.encoder_last_hidden_state, dim=1)\n",
    "embedding = outputs.encoder_last_hidden_state[:, 0, :]\n",
    "logits = self.classifier(embedding)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a07c98-3222-4715-9f9f-fd42e3878eb5",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a818de-e1bb-4bac-8bf2-a0cc522602b7",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
