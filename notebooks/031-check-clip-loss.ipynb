{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ef062a-714f-47ad-a4e4-59506da89d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau, LinearLR\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from core.final.dataset import PSMDataset\n",
    "from core.final.model import Informer, GalSpecNet, MetaModel, AstroModel\n",
    "from core.final.loss import CLIPLoss\n",
    "from core.final.trainer import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2345c300-1635-4828-a7dd-5e6fd343b8a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['EW', 'SR', 'EA', 'RRAB', 'EB', 'ROT', 'RRC', 'HADS', 'M', 'DSCT']\n",
    "METADATA_COLS = [\n",
    "    'mean_vmag',  'phot_g_mean_mag', 'e_phot_g_mean_mag', 'phot_bp_mean_mag', 'e_phot_bp_mean_mag', 'phot_rp_mean_mag',\n",
    "    'e_phot_rp_mean_mag', 'bp_rp', 'parallax', 'parallax_error', 'parallax_over_error', 'pmra', 'pmra_error', 'pmdec',\n",
    "    'pmdec_error', 'j_mag', 'e_j_mag', 'h_mag', 'e_h_mag', 'k_mag', 'e_k_mag', 'w1_mag', 'e_w1_mag',\n",
    "    'w2_mag', 'e_w2_mag', 'w3_mag', 'w4_mag', 'j_k', 'w1_w2', 'w3_w4', 'pm', 'ruwe', 'l', 'b'\n",
    "]\n",
    "PHOTO_COLS = ['amplitude', 'period', 'lksl_statistic', 'rfr_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "855f584a-af99-4459-928a-2a0d28f1f2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(config):\n",
    "    if config['mode'] == 'photo':\n",
    "        model = Informer(config)\n",
    "    elif config['mode'] == 'spectra':\n",
    "        model = GalSpecNet(config)\n",
    "    elif config['mode'] == 'meta':\n",
    "        model = MetaModel(config)\n",
    "    else:\n",
    "        model = AstroModel(config)\n",
    "\n",
    "    if config['use_pretrain'] and config['use_pretrain'].startswith('CLIP'):\n",
    "        weights = torch.load(config['use_pretrain'][4:], weights_only=True)\n",
    "\n",
    "        if config['mode'] == 'photo':\n",
    "            weights_prefix = 'photometry_encoder'\n",
    "        elif config['mode'] == 'spectra':\n",
    "            weights_prefix = 'spectra_encoder'\n",
    "        elif config['mode'] == 'meta':\n",
    "            weights_prefix = 'metadata_encoder'\n",
    "        else:\n",
    "            weights_prefix = None\n",
    "\n",
    "        if weights_prefix:\n",
    "            weights = {k[len(weights_prefix) + 1:]: v for k, v in weights.items() if k.startswith(weights_prefix)}\n",
    "\n",
    "        model.load_state_dict(weights, strict=False)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_schedulers(config, optimizer):\n",
    "    if config['scheduler'] == 'ExponentialLR':\n",
    "        scheduler = ExponentialLR(optimizer, gamma=config['gamma'])\n",
    "    elif config['scheduler'] == 'ReduceLROnPlateau':\n",
    "        scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=config['factor'], patience=config['patience'])\n",
    "    else:\n",
    "        raise NotImplementedError(f\"Scheduler {config['scheduler']} not implemented\")\n",
    "\n",
    "    if config['warmup']:\n",
    "        warmup_scheduler = LinearLR(optimizer, start_factor=1e-5, end_factor=1, total_iters=config['warmup_epochs'])\n",
    "    else:\n",
    "        warmup_scheduler = None\n",
    "\n",
    "    return scheduler, warmup_scheduler\n",
    "\n",
    "\n",
    "def set_random_seeds(random_seed):\n",
    "    torch.manual_seed(random_seed)\n",
    "    torch.cuda.manual_seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "def get_config():\n",
    "    config = {\n",
    "        'project': 'AstroCLIPResults',\n",
    "        'mode': 'clip',    # 'clip' 'photo' 'spectra' 'meta' 'all'\n",
    "        'config_from': None,    # 'meridk/AstroCLIPResults/d2u52yml',\n",
    "        'random_seed': 42,  # 42, 66, 0, 12, 123\n",
    "        'use_wandb': True,\n",
    "        'save_weights': False,\n",
    "        'weights_path': f'/home/mariia/AstroML/weights/{datetime.now().strftime(\"%Y-%m-%d-%H-%M\")}',\n",
    "        # 'use_pretrain': 'CLIP/home/mariia/AstroML/weights/2024-08-14-14-05-zmjau1cu/weights-51.pth',\n",
    "        'use_pretrain': None,\n",
    "        'freeze': False,\n",
    "\n",
    "        # Data General\n",
    "        'data_root': '/home/mariia/AstroML/data/asassn/',\n",
    "        'file': 'preprocessed_data/full_lb/spectra_and_v',\n",
    "        'classes': CLASSES,\n",
    "        'num_classes': len(CLASSES),\n",
    "        'meta_cols': METADATA_COLS,\n",
    "        'photo_cols': PHOTO_COLS,\n",
    "        'min_samples': None,\n",
    "        'max_samples': None,\n",
    "\n",
    "        # Photometry\n",
    "        'v_zip': 'asassnvarlc_vband_complete.zip',\n",
    "        'v_prefix': 'vardb_files',\n",
    "        'seq_len': 200,\n",
    "        'phased': False,\n",
    "        'p_aux': True,\n",
    "\n",
    "        # Spectra\n",
    "        'lamost_spec_dir': 'Spectra/v2',\n",
    "        's_mad': True,     # if True use mad for norm else std\n",
    "        's_aux': True,\n",
    "        's_err': True,\n",
    "        's_err_norm': True,\n",
    "\n",
    "        # Photometry Model\n",
    "        'p_enc_in': 3,\n",
    "        'p_d_model': 128,\n",
    "        'p_dropout': 0.2,\n",
    "        'p_factor': 1,\n",
    "        'p_output_attention': False,\n",
    "        'p_n_heads': 4,\n",
    "        'p_d_ff': 512,\n",
    "        'p_activation': 'gelu',\n",
    "        'p_e_layers': 8,\n",
    "\n",
    "        # Spectra Model\n",
    "        's_dropout': 0.2,\n",
    "        's_conv_channels': [1, 64, 64, 32, 32],\n",
    "        's_kernel_size': 3,\n",
    "        's_mp_kernel_size': 4,\n",
    "\n",
    "        # Metadata Model\n",
    "        'm_hidden_dim': 512,\n",
    "        'm_dropout': 0.2,\n",
    "\n",
    "        # MultiModal Model\n",
    "        'hidden_dim': 512,\n",
    "        'fusion': 'avg',  # 'avg', 'concat'\n",
    "\n",
    "        # Training\n",
    "        'batch_size': 512,\n",
    "        'lr': 0.001,\n",
    "        'beta1': 0.9,\n",
    "        'beta2': 0.999,\n",
    "        'weight_decay': 0.01,\n",
    "        'epochs': 100,\n",
    "        'early_stopping_patience': 6,\n",
    "        'scheduler': 'ReduceLROnPlateau',  # 'ExponentialLR', 'ReduceLROnPlateau'\n",
    "        'gamma': 0.9,  # for ExponentialLR scheduler\n",
    "        'factor': 0.3,  # for ReduceLROnPlateau scheduler\n",
    "        'patience': 3,  # for ReduceLROnPlateau scheduler\n",
    "        'warmup': True,\n",
    "        'warmup_epochs': 10,\n",
    "        'clip_grad': True,\n",
    "        'clip_value': 5\n",
    "    }\n",
    "\n",
    "    if config['p_aux']:\n",
    "        config['p_enc_in'] += len(config['photo_cols']) + 2     # +2 for mad and delta t\n",
    "\n",
    "    if config['s_aux']:\n",
    "        config['s_conv_channels'][0] += 1\n",
    "\n",
    "    if config['s_err']:\n",
    "        config['s_conv_channels'][0] += 1\n",
    "\n",
    "    if config['config_from']:\n",
    "        print(f\"Copying params from the {config['config_from']} run\")\n",
    "        old_config = wandb.Api().run(config['config_from']).config\n",
    "\n",
    "        for el in old_config:\n",
    "            if el in [\n",
    "                'p_dropout', 's_dropout', 'm_dropout', 'lr', 'beta1', 'weight_decay', 'epochs',\n",
    "                'early_stopping_patience', 'factor', 'patience', 'warmup', 'warmup_epochs', 'clip_grad', 'clip_value',\n",
    "                'use_pretrain', 'freeze', 'phased', 'p_aux', 's_aux', 's_err',\n",
    "            ]:\n",
    "                config[el] = old_config[el]\n",
    "\n",
    "    config['clip_grad'] = True\n",
    "    config['clip_value'] = 5\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "055d02af-d9fc-4906-a7de-4e22bb2fdcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "set_random_seeds(config['random_seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98ff208e-c6a4-4834-945e-c7e7e5916e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "train_dataset = PSMDataset(config, split='train')\n",
    "val_dataset = PSMDataset(config, split='val')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=config['batch_size'], shuffle=True, num_workers=4, drop_last=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=config['batch_size'], shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c4208324-771a-4feb-b1a5-4ecf67616ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(config)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=config['lr'], betas=(config['beta1'], config['beta2']),\n",
    "                 weight_decay=config['weight_decay'])\n",
    "scheduler, warmup_scheduler = get_schedulers(config, optimizer)\n",
    "criterion = CLIPLoss() if config['mode'] == 'clip' else torch.nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = Trainer(model=model, optimizer=optimizer, scheduler=scheduler, warmup_scheduler=warmup_scheduler,\n",
    "                  criterion=criterion, device=device, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f9495bd2-7b5e-48fe-925d-f9a248295856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(train_dataloader):\n",
    "    losses = {'step_loss': [], 'loss_ps': [], 'loss_sm': [], 'loss_mp': []}\n",
    "    \n",
    "    trainer.model.train()\n",
    "    trainer.zero_stats()\n",
    "\n",
    "    for photometry, photometry_mask, spectra, metadata, labels in tqdm(train_dataloader):\n",
    "        photometry, photometry_mask = photometry.to(trainer.device), photometry_mask.to(trainer.device)\n",
    "        spectra, metadata, labels = spectra.to(trainer.device), metadata.to(trainer.device), labels.to(trainer.device)\n",
    "\n",
    "        trainer.optimizer.zero_grad()\n",
    "        loss, loss_ps, loss_sm, loss_mp = trainer.step_clip(photometry, photometry_mask, spectra, metadata)\n",
    "        \n",
    "        losses['step_loss'].append(loss.item())\n",
    "        losses['loss_ps'].append(loss_ps.item())\n",
    "        losses['loss_sm'].append(loss_sm.item())\n",
    "        losses['loss_mp'].append(loss_mp.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(trainer.model.parameters(), trainer.clip_value)\n",
    "        trainer.optimizer.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56011351-bcfd-41e7-b732-3074f6abb0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [02:05<00:00,  3.79s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [01:53<00:00,  3.44s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [01:58<00:00,  3.59s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [02:02<00:00,  3.71s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [01:56<00:00,  3.52s/it]\n"
     ]
    }
   ],
   "source": [
    "all_losses = []\n",
    "\n",
    "for i in range(5):\n",
    "    losses = train_epoch(train_dataloader)\n",
    "    all_losses.append(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3c31dfc-5ec8-4aa6-bf74-9db2f6d56e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 33/33 [01:55<00:00,  3.50s/it]\n"
     ]
    }
   ],
   "source": [
    "last_batch = None\n",
    "\n",
    "for batch in tqdm(train_dataloader):\n",
    "    last_batch = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb13cfe6-6ec7-4369-8366-f2c958cd94a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 200, 9])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3519151f-5114-4191-b84b-5087b3065aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 200, 9])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = next(iter(train_dataloader))\n",
    "first_batch[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c6f188-5825-43f5-bf08-bb091133e786",
   "metadata": {},
   "outputs": [],
   "source": [
    "[el['step_loss'] for el in all_losses]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b47968-80f0-4db7-81e9-5d4c3f2c368e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ae0d37-7f93-4a27-aad0-e9b47d13dc50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81a0cbf-0df7-4b21-9ec7-f914299c7ebd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107166c5-ff3a-4450-b7a2-b7a31af3b0b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d7d29e-94cd-4143-9ff3-0b6f4f53cf63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef04a1c-970b-4a20-bc22-4fb73df63b0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb6c529-1465-40a9-829b-062cf5dfb000",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea4b18b-fe8a-4417-a37d-47ce8aeb60b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea913cfb-98e3-4be7-bbd1-f93b3b849473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b2d0c5-331e-4f80-87ac-3cc7df5a2865",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3945387-45be-425a-bc07-866e97eff531",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
