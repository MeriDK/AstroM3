{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a36031f4-4278-4477-97d4-189fd71e7412",
   "metadata": {},
   "source": [
    "# Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adb1b2f5-e7e4-4271-9986-d81ce724ce2a",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "print(os.environ.get('CONDA_DEFAULT_ENV'))"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4a2d992-5147-49e1-9bc2-cb0c2d4b062f",
   "metadata": {},
   "source": [
    "import joblib\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from evaluate import load\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import PretrainedConfig\n",
    "from transformers import TimeSeriesTransformerConfig, TimeSeriesTransformerForPrediction\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12e503c8-1000-4d90-9066-453bc5a2e200",
   "metadata": {},
   "source": [
    "class MachoDataset(Dataset):\n",
    "    def __init__(self, data_root, prediction_length, mode='train'):\n",
    "        data = joblib.load(data_root + f'{mode}.pkl')\n",
    "        self.prediction_length = prediction_length\n",
    "        \n",
    "        self.times = data[0][:, 0, :]\n",
    "        self.values = data[0][:, 1, :]\n",
    "        self.aux = data[1]\n",
    "        self.labels = data[2]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        past_times = torch.tensor(self.times[idx, :-self.prediction_length], dtype=torch.float)\n",
    "        future_times = torch.tensor(self.times[idx, -self.prediction_length:], dtype=torch.float)\n",
    "        past_values = torch.tensor(self.values[idx, :-self.prediction_length], dtype=torch.float)\n",
    "        future_values = torch.tensor(self.values[idx, -self.prediction_length:], dtype=torch.float)\n",
    "        past_mask = torch.ones(past_times.shape, dtype=torch.float)\n",
    "        future_mask = torch.ones(future_times.shape, dtype=torch.float)\n",
    "        labels = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        past_times = past_times.unsqueeze(-1)\n",
    "        future_times = future_times.unsqueeze(-1)\n",
    "\n",
    "        return past_times, future_times, past_values, future_values, past_mask, future_mask, labels"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3163fead-df60-4c55-83ee-46a70c680c75",
   "metadata": {},
   "source": [
    "data_root = '/home/mrizhko/AstroML/contra_periodic/data/macho/'\n",
    "window_length = 200\n",
    "prediction_length = 1"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7ef9300-7eba-440c-8379-ed7633f93130",
   "metadata": {},
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94eb8230-7436-40db-8c1a-7894a708801a",
   "metadata": {},
   "source": [
    "train_dataset = MachoDataset(data_root, prediction_length, mode='train')\n",
    "val_dataset = MachoDataset(data_root, prediction_length, mode='val')\n",
    "test_dataset = MachoDataset(data_root, prediction_length, mode='test')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5ef610f-643f-46ba-a9e0-e1ad36759792",
   "metadata": {},
   "source": [
    "len(train_dataset)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca9ada3-2eea-4cd1-a413-0ad275b11ed7",
   "metadata": {},
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=256, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=256, shuffle=False)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b0d37ca-db8b-41eb-a139-687af2493d95",
   "metadata": {},
   "source": [
    "past_times, future_times, past_values, future_values, past_mask, future_mask, labels = train_dataset[0]"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "07109c28-7361-4b19-97db-7bc5b9f3e338",
   "metadata": {},
   "source": [
    "# Time Series Prediction Model Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee2adbed-07c2-4ad5-ba06-8fd6785be008",
   "metadata": {},
   "source": [
    "def train_step(train_dataloader, model, optimizer):\n",
    "    total_loss = []\n",
    "    \n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        past_times, future_times, past_values, future_values, past_mask, future_mask, _ = batch\n",
    "        \n",
    "        outputs = model(\n",
    "            past_time_features=past_times.to(device),\n",
    "            past_values=past_values.to(device),\n",
    "            future_time_features=future_times.to(device),\n",
    "            future_values=future_values.to(device),\n",
    "            past_observed_mask=past_mask.to(device),\n",
    "            future_observed_mask=future_mask.to(device),\n",
    "        )\n",
    "\n",
    "        loss = outputs.loss\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return sum(total_loss) / len(total_loss)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5def6e51-6f91-466d-96c0-8b4283d44b0c",
   "metadata": {},
   "source": [
    "def val_step(val_dataloader, model):\n",
    "    total_loss = []\n",
    "\n",
    "    for idx, batch in enumerate(val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            past_times, future_times, past_values, future_values, past_mask, future_mask, _ = batch\n",
    "            \n",
    "            outputs = model(\n",
    "                past_time_features=past_times.to(device),\n",
    "                past_values=past_values.to(device),\n",
    "                future_time_features=future_times.to(device),\n",
    "                future_values=future_values.to(device),\n",
    "                past_observed_mask=past_mask.to(device),\n",
    "                future_observed_mask=future_mask.to(device),\n",
    "            )\n",
    "        \n",
    "            loss = outputs.loss\n",
    "            total_loss.append(loss.item())\n",
    "            \n",
    "    return sum(total_loss) / len(total_loss)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ed4a1bb-c98a-4c57-9400-c25eeb68b8e3",
   "metadata": {},
   "source": [
    "config = TimeSeriesTransformerConfig(\n",
    "    prediction_length=prediction_length,\n",
    "    context_length=window_length - prediction_length - 7,    # 7 is max(lags) for default lags\n",
    "    num_time_features=1,\n",
    "    encoder_layers=2,\n",
    "    decoder_layers=2,\n",
    "    d_model=64,\n",
    ")\n",
    "\n",
    "model = TimeSeriesTransformerForPrediction(config)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc30511-7e88-4297-8367-82e84789f617",
   "metadata": {},
   "source": [
    "model = model.to(device)\n",
    "optimizer = AdamW(model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a96adee6-8fde-4b46-b6bb-b3c9d3e48be5",
   "metadata": {},
   "source": [
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(10):\n",
    "    model.train()\n",
    "    train_loss = train_step(train_dataloader, model, optimizer)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = val_step(val_dataloader, model)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch {epoch}: Train Loss {round(train_loss, 4)} Val Loss {round(val_loss, 4)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a7a8e896-db33-4012-98c8-dc5edce22917",
   "metadata": {},
   "source": [
    "epochs = range(10)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9bc2afe6-4c6a-45f1-a372-92b28a265e2f",
   "metadata": {},
   "source": [
    "model.save_pretrained('weights/model.ckpt')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "db62e2cb-7fc8-48af-81b5-cc93be079df1",
   "metadata": {},
   "source": [
    "# Time Series Prediction Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b37a0c2-677f-42b9-9d70-f8c0350fc55f",
   "metadata": {},
   "source": [
    "def get_forecasts(model, val_dataloader):\n",
    "    forecasts = []\n",
    "\n",
    "    for idx, batch in enumerate(val_dataloader):\n",
    "        with torch.no_grad():\n",
    "            past_times, future_times, past_values, future_values, past_mask, future_mask, label = batch\n",
    "            \n",
    "            outputs = model.generate(\n",
    "                past_time_features=past_times.to(device),\n",
    "                past_values=past_values.to(device),\n",
    "                future_time_features=future_times.to(device),\n",
    "                past_observed_mask=past_mask.to(device),\n",
    "            )\n",
    "            \n",
    "            forecasts.append(outputs.sequences.cpu().numpy())\n",
    "    \n",
    "    forecasts = np.vstack(forecasts)\n",
    "    forecast_median = np.median(forecasts, 1)\n",
    "\n",
    "    return forecast_median"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c20108-72e7-4205-9778-c9ff822af3a6",
   "metadata": {},
   "source": [
    "def get_metrics(val_dataset, forecasts):\n",
    "    mase_metric = load('evaluate-metric/mase')\n",
    "    smape_metric = load('evaluate-metric/smape')\n",
    "    \n",
    "    mase_metrics = []\n",
    "    smape_metrics = []\n",
    "    \n",
    "    for i, ts in enumerate(tqdm(val_dataset)):\n",
    "        _, _, past_values, future_values, _, _, _ = val_dataset[i]\n",
    "    \n",
    "        mase = mase_metric.compute(\n",
    "            predictions=forecasts[i],\n",
    "            references=np.array(future_values),\n",
    "            training=np.array(past_values)\n",
    "        )\n",
    "        mase_metrics.append(mase['mase'])\n",
    "    \n",
    "        smape = smape_metric.compute(\n",
    "            predictions=forecasts[i],\n",
    "            references=np.array(future_values),\n",
    "        )\n",
    "        smape_metrics.append(smape['smape'])\n",
    "\n",
    "    return np.mean(mase_metrics), np.mean(smape_metrics)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ec18103-4aec-462f-9e87-bc5ed72b747b",
   "metadata": {},
   "source": [
    "model = TimeSeriesTransformerForPrediction.from_pretrained('weights/model.ckpt')\n",
    "model = model.to(device)"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6ac87b5b-90fe-49ea-8b72-5c8519abb6dd",
   "metadata": {},
   "source": [
    "model.eval()\n",
    "\n",
    "forecasts = get_forecasts(model, val_dataloader)\n",
    "mase, smape = get_metrics(val_dataset, forecasts)\n",
    "\n",
    "print(f'MASE: {mase} sMAPE: {smape}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "791e64ec-1a7a-484c-80e7-e43ab61bddf6",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4db1c2e4-f781-446b-a439-817f78c6cf23",
   "metadata": {},
   "source": [
    "class ClassificationModel(nn.Module):\n",
    "    def __init__(self, pretrained_model_path, device, hidden_size=64, num_labels=8):\n",
    "        super(ClassificationModel, self).__init__()\n",
    "\n",
    "        self.pretrained_model = TimeSeriesTransformerForPrediction.from_pretrained(pretrained_model_path)\n",
    "        self.pretrained_model.to(device)\n",
    "        self.device = device\n",
    "        \n",
    "        # for param in self.pretrained_model.parameters():\n",
    "        #     param.requires_grad = False\n",
    "            \n",
    "        self.classifier = nn.Linear(hidden_size, num_labels)\n",
    "        self.classifier.to(self.device)\n",
    "        \n",
    "    def forward(self, past_times, past_values, future_times, past_mask):   \n",
    "        outputs = self.pretrained_model(\n",
    "            past_time_features=past_times.to(self.device),\n",
    "            past_values=past_values.to(self.device),\n",
    "            future_time_features=future_times.to(self.device),\n",
    "            past_observed_mask=past_mask.to(self.device),\n",
    "        )\n",
    "    \n",
    "        # embedding = torch.mean(outputs.encoder_last_hidden_state, dim=1)        \n",
    "        embedding = outputs.encoder_last_hidden_state[:, 0, :]\n",
    "        logits = self.classifier(embedding)\n",
    "        \n",
    "        return logits"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1c2b8354-adde-4610-863a-c73f11796ef3",
   "metadata": {},
   "source": [
    "def cl_train_step(train_dataloader, cl_model, cl_optimizer, cl_loss):\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    for batch in train_dataloader:\n",
    "        past_times, future_times, past_values, future_values, past_mask, future_mask, labels = batch\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        cl_optimizer.zero_grad()\n",
    "\n",
    "        logits = cl_model(past_times, past_values, future_times, past_mask)\n",
    "        loss = cl_loss(logits, labels)\n",
    "        total_loss.append(loss.item())\n",
    "\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "        correct_predictions = (predicted_labels == labels).sum().item()\n",
    "        \n",
    "        total_correct_predictions += correct_predictions\n",
    "        total_predictions += labels.size(0)\n",
    "        \n",
    "        loss.backward()\n",
    "        cl_optimizer.step()\n",
    "\n",
    "    return sum(total_loss) / len(total_loss), total_correct_predictions / total_predictions"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87e60ad2-24e8-4ac6-b2d5-66d775f31a10",
   "metadata": {},
   "source": [
    "def cl_val_step(val_dataloader, cl_model, cl_loss):\n",
    "    total_loss = []\n",
    "    total_correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            past_times, future_times, past_values, future_values, past_mask, future_mask, labels = batch\n",
    "            labels = labels.to(device)\n",
    "                \n",
    "            logits = cl_model(past_times, past_values, future_times, past_mask)\n",
    "            loss = cl_loss(logits, labels)\n",
    "            total_loss.append(loss.item())\n",
    "    \n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "            _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "            correct_predictions = (predicted_labels == labels).sum().item()\n",
    "            \n",
    "            total_correct_predictions += correct_predictions\n",
    "            total_predictions += labels.size(0)\n",
    "            \n",
    "    return sum(total_loss) / len(total_loss), total_correct_predictions / total_predictions"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08c38180-94ee-4b2f-959b-6a982692cbb4",
   "metadata": {},
   "source": [
    "cl_model = ClassificationModel(pretrained_model_path='weights/model.ckpt', device=device)\n",
    "cl_optimizer = AdamW(cl_model.parameters(), lr=6e-4, betas=(0.9, 0.95), weight_decay=1e-1)\n",
    "cl_loss = nn.CrossEntropyLoss()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4f7723e0-a252-47fa-8e11-7f84183002b7",
   "metadata": {},
   "source": [
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    train_loss, train_acc = cl_train_step(train_dataloader, cl_model, cl_optimizer, cl_loss)\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss, val_acc = cl_val_step(val_dataloader, cl_model, cl_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch {epoch}: Train Loss {round(train_loss, 4)} \\t Val Loss {round(val_loss, 4)} \\t \\\n",
    "            Train Acc {round(train_acc, 4)} \\t Val Acc {round(val_acc, 4)}')"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "79e083fa-7fb5-4f19-92af-a52394642b68",
   "metadata": {},
   "source": [
    "epochs = range(len(train_losses))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot training and validation losses\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label='Training Loss')\n",
    "plt.plot(epochs, val_losses, label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# Plot training and validation accuracies\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs, val_accuracies, label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36efe0b-461e-4d39-850d-356a79531a5b",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02105cc2-338f-49e1-b641-7f5ebc8b2470",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "5933aef6-1bde-4a89-9367-c2465f28761b",
   "metadata": {},
   "source": [
    "# Evaluate Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd920b36-3594-4756-963d-e6e942d91c66",
   "metadata": {},
   "source": [
    "cl_model.eval()\n",
    "\n",
    "all_true_labels = []\n",
    "all_predicted_labels = []\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    with torch.no_grad():\n",
    "        past_times, future_times, past_values, future_values, past_mask, future_mask, label = batch\n",
    "        label = label.to(device)\n",
    "        \n",
    "        logits = cl_model(past_times, past_values, future_times, past_mask)\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "        _, predicted_labels = torch.max(probabilities, dim=1)\n",
    "\n",
    "        all_true_labels.extend(label.cpu().numpy())\n",
    "        all_predicted_labels.extend(predicted_labels.cpu().numpy())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5de559f2-91d4-4738-812e-b41bfcaf2124",
   "metadata": {},
   "source": [
    "conf_matrix = confusion_matrix(all_true_labels, all_predicted_labels)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c90ea4-0347-444a-a641-268586576a36",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d75401-db3e-4c8f-b168-dc5199e5422b",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf1c2d-d3d4-40d8-a3e7-f7abd290f618",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc72de10-2d12-4af9-9513-48fcb16097b3",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ee8b27-c59e-43de-999f-c421e33d3ac8",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ffd576-5d1a-4604-97c6-81bd9e8b2952",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66d90f3c-9b9a-418d-a0c4-1f32ea4d96aa",
   "metadata": {},
   "source": [],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a056df48-a744-4800-864d-05b4c08ec5e0",
   "metadata": {},
   "source": [],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
